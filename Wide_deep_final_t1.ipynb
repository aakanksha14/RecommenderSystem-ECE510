{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide-deep-final_t1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "orw-bvzJ-oei",
        "colab_type": "code",
        "outputId": "b49d5e87-8171-458a-b04c-59c955a169fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjzpHGYv-hug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from pathlib import PosixPath\n",
        "from typing import List, Any, Union, Dict, Optional, Tuple, Generator, Collection\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm,trange\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
        "\n",
        "LRScheduler = _LRScheduler\n",
        "ModelParams = Generator[Tensor,Tensor,Tensor]\n",
        "\n",
        "plot_epoch_t = []\n",
        "plot_train_loss =[]\n",
        "plot_epoch_v = []\n",
        "plot_val_loss = []\n",
        "        \n",
        "      \n",
        "# This is related to wide neural network\n",
        "class wide(nn.Module):\n",
        "    # num_input = number of input\n",
        "    # num_output = number of output\n",
        "    def __init__(self,num_input,num_output):\n",
        "        super(wide, self).__init__()\n",
        "        self.widenn = nn.Linear(num_input,num_output)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.widenn(x)\n",
        "        return out\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc40OVhv-huj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_layer(layer_in,layer_out,dropout):\n",
        "    ly = nn.Sequential(nn.Linear(layer_in, layer_out),nn.LeakyReLU(inplace=True), nn.Dropout(dropout))\n",
        "    return ly\n",
        "\n",
        "# Deep neural network\n",
        "# Code for deep neural network taken from Wide-and-Deep-PyTorch and edited for our dataset\n",
        "class deep(nn.Module):\n",
        "    \n",
        "    # For regression output dimention is 1\n",
        "    def __init__(self, embeddings_input:List[Tuple[str,int,int]],\n",
        "        embeddings_encoding_dict:Dict[str,Any], continuous_cols:List[str],\n",
        "        deep_column_idx:Dict[str,int], hidden_layers:List[int], dropout:List[float],\n",
        "        output_dim=1):\n",
        "        \n",
        "        super(deep, self).__init__()\n",
        "\n",
        "        self.embeddings_input = embeddings_input\n",
        "        self.embeddings_encoding_dict = embeddings_encoding_dict\n",
        "        self.continuous_cols = continuous_cols\n",
        "        self.deep_column_idx = deep_column_idx\n",
        "\n",
        "        for col,val,dim in embeddings_input:\n",
        "            setattr(self, 'emb_layer_'+col, nn.Embedding(val, dim))\n",
        "        input_emb_dim = np.sum([emb[2] for emb in embeddings_input])+len(continuous_cols)\n",
        "        hidden_layers = [input_emb_dim] + hidden_layers\n",
        "        dropout = [0.0] + dropout\n",
        "        self.dense = nn.Sequential()\n",
        "        for i in range(1, len(hidden_layers)):\n",
        "            self.dense.add_module(\n",
        "                'deep_layer{}'.format(i-1),\n",
        "                deep_layer( hidden_layers[i-1], hidden_layers[i], dropout[i-1])\n",
        "                )\n",
        "        self.dense.add_module('last_linear', nn.Linear(hidden_layers[-1], output_dim))\n",
        "\n",
        "    def forward(self, X:Tensor)->Tensor:\n",
        "        emb = [getattr(self, 'emb_layer_'+col)(X[:,self.deep_column_idx[col]].long())\n",
        "               for col,_,_ in self.embeddings_input]\n",
        "        if self.continuous_cols:\n",
        "            cont_idx = [self.deep_column_idx[col] for col in self.continuous_cols]\n",
        "            cont = [X[:, cont_idx].float()]\n",
        "            inp = torch.cat(emb+cont, 1)\n",
        "        else:\n",
        "            inp = torch.cat(emb, 1)\n",
        "        out = self.dense(inp)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npp_ToYy-hum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining wide and deep neural networks\n",
        "\n",
        "class widedeep(nn.Module):\n",
        "    def __init__(self,**params):\n",
        "        super(widedeep,self).__init__()\n",
        "        \n",
        "        self.datasets = {} # dictionary 2 -> wide dataset and deep dataset\n",
        "        self.out_dim = 1 # for regression (predicts the user rate)\n",
        "        self.n_datasets = 1\n",
        "        \n",
        "        # Get parameters for wide dataset\n",
        "        for key,val in params['wide'].items():\n",
        "            setattr(self, key, val) # we are getting wide_dim\n",
        "            \n",
        "        # instantiation of wide objects\n",
        "        self.widenn = wide(\n",
        "            self.wide_dim,\n",
        "            self.out_dim\n",
        "            )\n",
        "        \n",
        "        # Get parameters for deep dataset\n",
        "        for key,val in params['deep'].items():\n",
        "            setattr(self, key, val)\n",
        "        self.datasets['deep'] = self.n_datasets\n",
        "        self.n_datasets+=1\n",
        "        self.deepnn = deep(\n",
        "            self.embeddings_input,\n",
        "            self.embeddings_encoding_dict,\n",
        "            self.continuous_cols,\n",
        "            self.deep_column_idx,\n",
        "            self.hidden_layers,\n",
        "            self.dropout,\n",
        "            self.out_dim\n",
        "        )\n",
        "        \n",
        "    def settings(self):\n",
        "#         method = 'regression'\n",
        "        method = 'logistic'\n",
        "        self.method = method\n",
        "        self.activation, self.criterion = None, F.mse_loss\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "        self.lr_scheduler = None\n",
        "        \n",
        "    def forward(self, X:Tuple[Tensor,...])->Tensor:\n",
        "        \n",
        "        # wide network\n",
        "        wide_input = X[0]\n",
        "        wide_deep = self.widenn(wide_input)\n",
        "        \n",
        "        # Deep network\n",
        "        deep_dense_idx = self.datasets['deep']\n",
        "        deep_dense_out = self.deepnn(X[0])\n",
        "        wide_deep.add_(deep_dense_out)\n",
        "        \n",
        "        # If no activation sigmoid etc. otherwise use activation funct.\n",
        "        return wide_deep\n",
        "    \n",
        "    def trainModel(self,n_epochs,train_loader,eval_loader=None):\n",
        "        train_steps =  (len(train_loader.dataset) // train_loader.batch_size) + 1\n",
        "        global plot_epoch_t,plot_epoch_v,plot_train_loss,plot_val_loss\n",
        "        \n",
        "        plot_epoch_t = []\n",
        "        plot_epoch_v = []\n",
        "        plot_train_loss =[]\n",
        "        plot_val_loss = []\n",
        "        \n",
        "        if eval_loader:\n",
        "            eval_steps =  (len(eval_loader.dataset) // eval_loader.batch_size) + 1\n",
        "            \n",
        "        for epoch in range(n_epochs):\n",
        "            if self.lr_scheduler: self.lr_scheduler.step()\n",
        "            net = self.train()\n",
        "            total, correct, running_loss = 0,0,0\n",
        "            with trange(train_steps) as t:\n",
        "                for i, (data,target) in zip(t, train_loader):\n",
        "                    t.set_description('epoch %i' % (epoch+1))\n",
        "                    X = tuple(x.cuda() for x in data) if use_cuda else data\n",
        "                    y = target.float() if self.method != 'multiclass' else target\n",
        "                    y = y.cuda() if use_cuda else y\n",
        "\n",
        "                    self.optimizer.zero_grad()\n",
        "                    y_pred =  net(X)\n",
        "                    if(self.criterion == F.cross_entropy):\n",
        "                        loss = self.criterion(y_pred, y)\n",
        "                    else:\n",
        "                        loss = self.criterion(y_pred, y.view(-1, 1))\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()\n",
        "                    avg_loss = running_loss/(i+1)\n",
        "\n",
        "                    if self.method != \"regression\":\n",
        "                        total+= y.size(0)\n",
        "                        if self.method == 'logistic':\n",
        "                            y_pred_cat = (y_pred > 0.5).squeeze(1).float()\n",
        "                        if self.method == \"multiclass\":\n",
        "                            _, y_pred_cat = torch.max(y_pred, 1)\n",
        "                        correct+= float((y_pred_cat == y).sum().item())\n",
        "                        t.set_postfix(acc=correct/total, loss=avg_loss)\n",
        "                    else:\n",
        "                        t.set_postfix(loss=np.sqrt(avg_loss))\n",
        "                    plot_epoch_t.append(epoch)\n",
        "                    plot_train_loss.append(avg_loss)\n",
        "\n",
        "            if eval_loader:\n",
        "                total, correct, running_loss = 0,0,0\n",
        "                net = self.eval()\n",
        "                with torch.no_grad():\n",
        "                    with trange(eval_steps) as v:\n",
        "                        for i, (data,target) in zip(v, eval_loader):\n",
        "                            v.set_description('valid')\n",
        "                            X = tuple(x.cuda() for x in data) if use_cuda else data\n",
        "                            y = target.float() if self.method != 'multiclass' else target\n",
        "                            y = y.cuda() if use_cuda else y\n",
        "                            y_pred =  net(X)\n",
        "                            if(self.criterion == F.cross_entropy):\n",
        "                                loss = self.criterion(y_pred, y)\n",
        "                            else:\n",
        "                                loss = self.criterion(y_pred, y.view(-1, 1))\n",
        "                            running_loss += loss.item()\n",
        "                            avg_loss = running_loss/(i+1)\n",
        "                            if self.method != \"regression\":\n",
        "                                total+= y.size(0)\n",
        "                                if self.method == 'logistic':\n",
        "                                    y_pred_cat = (y_pred > 0.5).squeeze(1).float()\n",
        "                                if self.method == \"multiclass\":\n",
        "                                    _, y_pred_cat = torch.max(y_pred, 1)\n",
        "                                correct+= float((y_pred_cat == y).sum().item())\n",
        "                                v.set_postfix(acc=correct/total, loss=avg_loss)\n",
        "                            else:\n",
        "                                v.set_postfix(loss=np.sqrt(avg_loss))\n",
        "                            plot_epoch_v.append(epoch)\n",
        "                            plot_val_loss.append(avg_loss)\n",
        "\n",
        "                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c1m7ZB10W8M",
        "colab_type": "code",
        "outputId": "22d0bee4-7ac0-4d8a-8890-8d8bb0de8866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WC7ffn_YM_",
        "colab_type": "code",
        "outputId": "b3234871-ac4a-4d5d-a31f-02c76b4aef25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd My\\ Drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw3TfHXi99t0",
        "colab_type": "code",
        "outputId": "c6bcdde1-abb3-47b7-eb88-49960e5f009e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd Wide-and-Deep-PyTorch/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Wide-and-Deep-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doacn11BD0am",
        "colab_type": "code",
        "outputId": "66096c4d-52db-4eda-cd4c-b9c8a09f06c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "data = pd.read_csv('data/IMDB/imdb.csv', header=0, error_bad_lines=False)\n",
        "data.columns = [c.replace(\"-\", \"_\") for c in data.columns]\n",
        "data[\"imdbRating\"] = data[\"imdbRating\"].fillna(0).astype(int)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 66: expected 44 fields, saw 46\\nSkipping line 111: expected 44 fields, saw 45\\nSkipping line 198: expected 44 fields, saw 45\\nSkipping line 222: expected 44 fields, saw 46\\nSkipping line 278: expected 44 fields, saw 45\\nSkipping line 396: expected 44 fields, saw 45\\nSkipping line 403: expected 44 fields, saw 45\\nSkipping line 421: expected 44 fields, saw 45\\nSkipping line 437: expected 44 fields, saw 45\\nSkipping line 462: expected 44 fields, saw 46\\nSkipping line 491: expected 44 fields, saw 45\\nSkipping line 515: expected 44 fields, saw 45\\nSkipping line 529: expected 44 fields, saw 45\\nSkipping line 530: expected 44 fields, saw 45\\nSkipping line 558: expected 44 fields, saw 45\\nSkipping line 623: expected 44 fields, saw 45\\nSkipping line 646: expected 44 fields, saw 45\\nSkipping line 663: expected 44 fields, saw 46\\nSkipping line 713: expected 44 fields, saw 45\\nSkipping line 730: expected 44 fields, saw 47\\nSkipping line 791: expected 44 fields, saw 45\\nSkipping line 813: expected 44 fields, saw 45\\nSkipping line 837: expected 44 fields, saw 45\\nSkipping line 861: expected 44 fields, saw 45\\nSkipping line 874: expected 44 fields, saw 45\\nSkipping line 899: expected 44 fields, saw 45\\nSkipping line 917: expected 44 fields, saw 45\\nSkipping line 944: expected 44 fields, saw 46\\nSkipping line 994: expected 44 fields, saw 45\\nSkipping line 1027: expected 44 fields, saw 45\\nSkipping line 1046: expected 44 fields, saw 45\\nSkipping line 1097: expected 44 fields, saw 45\\nSkipping line 1106: expected 44 fields, saw 45\\nSkipping line 1170: expected 44 fields, saw 45\\nSkipping line 1194: expected 44 fields, saw 45\\nSkipping line 1195: expected 44 fields, saw 45\\nSkipping line 1218: expected 44 fields, saw 45\\nSkipping line 1220: expected 44 fields, saw 45\\nSkipping line 1270: expected 44 fields, saw 45\\nSkipping line 1338: expected 44 fields, saw 47\\nSkipping line 1355: expected 44 fields, saw 45\\nSkipping line 1363: expected 44 fields, saw 45\\nSkipping line 1395: expected 44 fields, saw 45\\nSkipping line 1402: expected 44 fields, saw 46\\nSkipping line 1418: expected 44 fields, saw 45\\nSkipping line 1431: expected 44 fields, saw 45\\nSkipping line 1617: expected 44 fields, saw 45\\nSkipping line 1663: expected 44 fields, saw 45\\nSkipping line 1742: expected 44 fields, saw 46\\nSkipping line 1766: expected 44 fields, saw 45\\nSkipping line 1799: expected 44 fields, saw 45\\nSkipping line 1867: expected 44 fields, saw 45\\nSkipping line 1899: expected 44 fields, saw 45\\nSkipping line 1900: expected 44 fields, saw 45\\nSkipping line 1901: expected 44 fields, saw 45\\nSkipping line 1907: expected 44 fields, saw 45\\nSkipping line 1913: expected 44 fields, saw 45\\nSkipping line 1924: expected 44 fields, saw 45\\nSkipping line 1939: expected 44 fields, saw 45\\nSkipping line 1945: expected 44 fields, saw 45\\nSkipping line 1982: expected 44 fields, saw 45\\nSkipping line 2023: expected 44 fields, saw 45\\nSkipping line 2028: expected 44 fields, saw 45\\nSkipping line 2054: expected 44 fields, saw 45\\nSkipping line 2076: expected 44 fields, saw 45\\nSkipping line 2081: expected 44 fields, saw 45\\nSkipping line 2092: expected 44 fields, saw 45\\nSkipping line 2107: expected 44 fields, saw 45\\nSkipping line 2160: expected 44 fields, saw 45\\nSkipping line 2260: expected 44 fields, saw 45\\nSkipping line 2261: expected 44 fields, saw 45\\nSkipping line 2289: expected 44 fields, saw 46\\nSkipping line 2290: expected 44 fields, saw 45\\nSkipping line 2349: expected 44 fields, saw 45\\nSkipping line 2395: expected 44 fields, saw 45\\nSkipping line 2507: expected 44 fields, saw 45\\nSkipping line 2584: expected 44 fields, saw 45\\nSkipping line 2588: expected 44 fields, saw 46\\nSkipping line 2595: expected 44 fields, saw 45\\nSkipping line 2604: expected 44 fields, saw 45\\nSkipping line 2622: expected 44 fields, saw 45\\nSkipping line 2661: expected 44 fields, saw 45\\nSkipping line 2714: expected 44 fields, saw 45\\nSkipping line 2722: expected 44 fields, saw 45\\nSkipping line 2776: expected 44 fields, saw 45\\nSkipping line 2806: expected 44 fields, saw 45\\nSkipping line 2826: expected 44 fields, saw 45\\nSkipping line 2882: expected 44 fields, saw 45\\nSkipping line 2909: expected 44 fields, saw 45\\nSkipping line 3005: expected 44 fields, saw 45\\nSkipping line 3019: expected 44 fields, saw 45\\nSkipping line 3052: expected 44 fields, saw 45\\nSkipping line 3062: expected 44 fields, saw 45\\nSkipping line 3086: expected 44 fields, saw 45\\nSkipping line 3089: expected 44 fields, saw 45\\nSkipping line 3134: expected 44 fields, saw 46\\nSkipping line 3157: expected 44 fields, saw 45\\nSkipping line 3163: expected 44 fields, saw 45\\nSkipping line 3177: expected 44 fields, saw 45\\nSkipping line 3190: expected 44 fields, saw 45\\nSkipping line 3205: expected 44 fields, saw 45\\nSkipping line 3209: expected 44 fields, saw 45\\nSkipping line 3238: expected 44 fields, saw 45\\nSkipping line 3242: expected 44 fields, saw 45\\nSkipping line 3255: expected 44 fields, saw 45\\nSkipping line 3303: expected 44 fields, saw 45\\nSkipping line 3314: expected 44 fields, saw 45\\nSkipping line 3322: expected 44 fields, saw 45\\nSkipping line 3358: expected 44 fields, saw 45\\nSkipping line 3360: expected 44 fields, saw 46\\nSkipping line 3377: expected 44 fields, saw 45\\nSkipping line 3413: expected 44 fields, saw 45\\nSkipping line 3481: expected 44 fields, saw 45\\nSkipping line 3496: expected 44 fields, saw 45\\nSkipping line 3719: expected 44 fields, saw 45\\nSkipping line 3792: expected 44 fields, saw 45\\nSkipping line 3807: expected 44 fields, saw 46\\nSkipping line 3858: expected 44 fields, saw 45\\nSkipping line 3864: expected 44 fields, saw 45\\nSkipping line 3902: expected 44 fields, saw 45\\nSkipping line 3943: expected 44 fields, saw 45\\nSkipping line 3969: expected 44 fields, saw 45\\nSkipping line 4024: expected 44 fields, saw 47\\nSkipping line 4044: expected 44 fields, saw 45\\nSkipping line 4045: expected 44 fields, saw 45\\nSkipping line 4112: expected 44 fields, saw 45\\nSkipping line 4149: expected 44 fields, saw 45\\nSkipping line 4280: expected 44 fields, saw 45\\nSkipping line 4282: expected 44 fields, saw 45\\nSkipping line 4308: expected 44 fields, saw 45\\nSkipping line 4377: expected 44 fields, saw 45\\nSkipping line 4390: expected 44 fields, saw 45\\nSkipping line 4404: expected 44 fields, saw 45\\nSkipping line 4416: expected 44 fields, saw 45\\nSkipping line 4423: expected 44 fields, saw 46\\nSkipping line 4540: expected 44 fields, saw 45\\nSkipping line 4554: expected 44 fields, saw 45\\nSkipping line 4556: expected 44 fields, saw 46\\nSkipping line 4572: expected 44 fields, saw 45\\nSkipping line 4593: expected 44 fields, saw 45\\nSkipping line 4614: expected 44 fields, saw 45\\nSkipping line 4688: expected 44 fields, saw 45\\nSkipping line 4750: expected 44 fields, saw 45\\nSkipping line 4764: expected 44 fields, saw 45\\nSkipping line 4765: expected 44 fields, saw 45\\nSkipping line 4849: expected 44 fields, saw 45\\nSkipping line 4865: expected 44 fields, saw 45\\nSkipping line 4892: expected 44 fields, saw 45\\nSkipping line 4893: expected 44 fields, saw 45\\nSkipping line 4897: expected 44 fields, saw 45\\nSkipping line 4923: expected 44 fields, saw 45\\nSkipping line 4956: expected 44 fields, saw 45\\nSkipping line 4957: expected 44 fields, saw 45\\nSkipping line 4962: expected 44 fields, saw 45\\nSkipping line 4967: expected 44 fields, saw 45\\nSkipping line 4971: expected 44 fields, saw 45\\nSkipping line 5057: expected 44 fields, saw 45\\nSkipping line 5061: expected 44 fields, saw 45\\nSkipping line 5097: expected 44 fields, saw 45\\nSkipping line 5125: expected 44 fields, saw 45\\nSkipping line 5180: expected 44 fields, saw 45\\nSkipping line 5207: expected 44 fields, saw 45\\nSkipping line 5339: expected 44 fields, saw 45\\nSkipping line 5426: expected 44 fields, saw 45\\nSkipping line 5474: expected 44 fields, saw 45\\nSkipping line 5511: expected 44 fields, saw 45\\nSkipping line 5561: expected 44 fields, saw 45\\nSkipping line 5563: expected 44 fields, saw 45\\nSkipping line 5689: expected 44 fields, saw 45\\nSkipping line 5725: expected 44 fields, saw 45\\nSkipping line 5759: expected 44 fields, saw 45\\nSkipping line 5796: expected 44 fields, saw 45\\nSkipping line 5829: expected 44 fields, saw 45\\nSkipping line 5854: expected 44 fields, saw 45\\nSkipping line 5886: expected 44 fields, saw 45\\nSkipping line 5899: expected 44 fields, saw 45\\nSkipping line 5901: expected 44 fields, saw 45\\nSkipping line 5970: expected 44 fields, saw 45\\nSkipping line 5996: expected 44 fields, saw 45\\nSkipping line 6085: expected 44 fields, saw 45\\nSkipping line 6087: expected 44 fields, saw 45\\nSkipping line 6095: expected 44 fields, saw 45\\nSkipping line 6096: expected 44 fields, saw 45\\nSkipping line 6098: expected 44 fields, saw 45\\nSkipping line 6115: expected 44 fields, saw 46\\nSkipping line 6158: expected 44 fields, saw 46\\nSkipping line 6174: expected 44 fields, saw 45\\nSkipping line 6187: expected 44 fields, saw 45\\nSkipping line 6218: expected 44 fields, saw 45\\nSkipping line 6266: expected 44 fields, saw 45\\nSkipping line 6275: expected 44 fields, saw 45\\nSkipping line 6279: expected 44 fields, saw 45\\nSkipping line 6296: expected 44 fields, saw 45\\nSkipping line 6471: expected 44 fields, saw 46\\nSkipping line 6494: expected 44 fields, saw 45\\nSkipping line 6497: expected 44 fields, saw 45\\nSkipping line 6614: expected 44 fields, saw 46\\nSkipping line 6714: expected 44 fields, saw 45\\nSkipping line 6727: expected 44 fields, saw 45\\nSkipping line 6752: expected 44 fields, saw 45\\nSkipping line 6763: expected 44 fields, saw 45\\nSkipping line 6817: expected 44 fields, saw 45\\nSkipping line 6853: expected 44 fields, saw 45\\nSkipping line 6904: expected 44 fields, saw 45\\nSkipping line 6914: expected 44 fields, saw 45\\nSkipping line 6948: expected 44 fields, saw 45\\nSkipping line 6969: expected 44 fields, saw 45\\nSkipping line 6979: expected 44 fields, saw 45\\nSkipping line 7010: expected 44 fields, saw 47\\nSkipping line 7024: expected 44 fields, saw 45\\nSkipping line 7036: expected 44 fields, saw 45\\nSkipping line 7069: expected 44 fields, saw 45\\nSkipping line 7146: expected 44 fields, saw 45\\nSkipping line 7168: expected 44 fields, saw 45\\nSkipping line 7170: expected 44 fields, saw 45\\nSkipping line 7317: expected 44 fields, saw 45\\nSkipping line 7399: expected 44 fields, saw 45\\nSkipping line 7402: expected 44 fields, saw 45\\nSkipping line 7496: expected 44 fields, saw 45\\nSkipping line 7584: expected 44 fields, saw 45\\nSkipping line 7666: expected 44 fields, saw 45\\nSkipping line 7690: expected 44 fields, saw 45\\nSkipping line 7704: expected 44 fields, saw 47\\nSkipping line 7738: expected 44 fields, saw 45\\nSkipping line 7773: expected 44 fields, saw 45\\nSkipping line 7803: expected 44 fields, saw 45\\nSkipping line 7839: expected 44 fields, saw 45\\nSkipping line 7850: expected 44 fields, saw 45\\nSkipping line 7910: expected 44 fields, saw 45\\nSkipping line 7942: expected 44 fields, saw 45\\nSkipping line 7959: expected 44 fields, saw 45\\nSkipping line 8024: expected 44 fields, saw 45\\nSkipping line 8026: expected 44 fields, saw 45\\nSkipping line 8028: expected 44 fields, saw 45\\nSkipping line 8033: expected 44 fields, saw 45\\nSkipping line 8052: expected 44 fields, saw 45\\nSkipping line 8129: expected 44 fields, saw 45\\nSkipping line 8138: expected 44 fields, saw 45\\nSkipping line 8160: expected 44 fields, saw 46\\nSkipping line 8244: expected 44 fields, saw 45\\nSkipping line 8255: expected 44 fields, saw 45\\nSkipping line 8390: expected 44 fields, saw 45\\nSkipping line 8400: expected 44 fields, saw 45\\nSkipping line 8429: expected 44 fields, saw 45\\nSkipping line 8446: expected 44 fields, saw 46\\nSkipping line 8565: expected 44 fields, saw 46\\nSkipping line 8622: expected 44 fields, saw 46\\nSkipping line 8658: expected 44 fields, saw 45\\nSkipping line 8742: expected 44 fields, saw 45\\nSkipping line 8748: expected 44 fields, saw 45\\nSkipping line 8802: expected 44 fields, saw 45\\nSkipping line 8844: expected 44 fields, saw 45\\nSkipping line 8874: expected 44 fields, saw 45\\nSkipping line 8882: expected 44 fields, saw 45\\nSkipping line 8885: expected 44 fields, saw 48\\nSkipping line 8910: expected 44 fields, saw 45\\nSkipping line 8923: expected 44 fields, saw 45\\nSkipping line 8947: expected 44 fields, saw 45\\nSkipping line 8958: expected 44 fields, saw 45\\nSkipping line 9039: expected 44 fields, saw 46\\nSkipping line 9090: expected 44 fields, saw 45\\nSkipping line 9112: expected 44 fields, saw 45\\nSkipping line 9137: expected 44 fields, saw 45\\nSkipping line 9201: expected 44 fields, saw 45\\nSkipping line 9257: expected 44 fields, saw 45\\nSkipping line 9272: expected 44 fields, saw 45\\nSkipping line 9390: expected 44 fields, saw 45\\nSkipping line 9487: expected 44 fields, saw 45\\nSkipping line 9518: expected 44 fields, saw 45\\nSkipping line 9554: expected 44 fields, saw 45\\nSkipping line 9576: expected 44 fields, saw 45\\nSkipping line 9671: expected 44 fields, saw 45\\nSkipping line 9690: expected 44 fields, saw 45\\nSkipping line 9758: expected 44 fields, saw 45\\nSkipping line 9759: expected 44 fields, saw 45\\nSkipping line 9767: expected 44 fields, saw 45\\nSkipping line 9776: expected 44 fields, saw 45\\nSkipping line 9805: expected 44 fields, saw 45\\nSkipping line 9834: expected 44 fields, saw 45\\nSkipping line 9837: expected 44 fields, saw 45\\nSkipping line 9854: expected 44 fields, saw 45\\nSkipping line 9890: expected 44 fields, saw 45\\nSkipping line 9897: expected 44 fields, saw 45\\nSkipping line 9957: expected 44 fields, saw 45\\nSkipping line 9979: expected 44 fields, saw 45\\nSkipping line 9980: expected 44 fields, saw 45\\nSkipping line 10001: expected 44 fields, saw 45\\nSkipping line 10002: expected 44 fields, saw 45\\nSkipping line 10023: expected 44 fields, saw 45\\nSkipping line 10032: expected 44 fields, saw 45\\nSkipping line 10051: expected 44 fields, saw 45\\nSkipping line 10059: expected 44 fields, saw 46\\nSkipping line 10086: expected 44 fields, saw 45\\nSkipping line 10102: expected 44 fields, saw 45\\nSkipping line 10118: expected 44 fields, saw 45\\nSkipping line 10184: expected 44 fields, saw 45\\nSkipping line 10199: expected 44 fields, saw 45\\nSkipping line 10204: expected 44 fields, saw 45\\nSkipping line 10218: expected 44 fields, saw 45\\nSkipping line 10224: expected 44 fields, saw 45\\nSkipping line 10294: expected 44 fields, saw 45\\nSkipping line 10296: expected 44 fields, saw 45\\nSkipping line 10331: expected 44 fields, saw 45\\nSkipping line 10342: expected 44 fields, saw 45\\nSkipping line 10351: expected 44 fields, saw 45\\nSkipping line 10414: expected 44 fields, saw 45\\nSkipping line 10430: expected 44 fields, saw 45\\nSkipping line 10463: expected 44 fields, saw 45\\nSkipping line 10478: expected 44 fields, saw 46\\nSkipping line 10533: expected 44 fields, saw 45\\nSkipping line 10536: expected 44 fields, saw 45\\nSkipping line 10539: expected 44 fields, saw 45\\nSkipping line 10549: expected 44 fields, saw 45\\nSkipping line 10582: expected 44 fields, saw 45\\nSkipping line 10588: expected 44 fields, saw 45\\nSkipping line 10598: expected 44 fields, saw 45\\nSkipping line 10660: expected 44 fields, saw 45\\nSkipping line 10733: expected 44 fields, saw 45\\nSkipping line 10806: expected 44 fields, saw 45\\nSkipping line 10862: expected 44 fields, saw 45\\nSkipping line 10905: expected 44 fields, saw 45\\nSkipping line 10993: expected 44 fields, saw 45\\nSkipping line 11070: expected 44 fields, saw 45\\nSkipping line 11084: expected 44 fields, saw 45\\nSkipping line 11110: expected 44 fields, saw 45\\nSkipping line 11123: expected 44 fields, saw 45\\nSkipping line 11128: expected 44 fields, saw 45\\nSkipping line 11129: expected 44 fields, saw 45\\nSkipping line 11196: expected 44 fields, saw 45\\nSkipping line 11210: expected 44 fields, saw 45\\nSkipping line 11254: expected 44 fields, saw 45\\nSkipping line 11290: expected 44 fields, saw 45\\nSkipping line 11365: expected 44 fields, saw 45\\nSkipping line 11433: expected 44 fields, saw 45\\nSkipping line 11434: expected 44 fields, saw 45\\nSkipping line 11469: expected 44 fields, saw 45\\nSkipping line 11475: expected 44 fields, saw 45\\nSkipping line 11480: expected 44 fields, saw 45\\nSkipping line 11513: expected 44 fields, saw 45\\nSkipping line 11522: expected 44 fields, saw 45\\nSkipping line 11553: expected 44 fields, saw 45\\nSkipping line 11610: expected 44 fields, saw 45\\nSkipping line 11641: expected 44 fields, saw 45\\nSkipping line 11655: expected 44 fields, saw 46\\nSkipping line 11689: expected 44 fields, saw 45\\nSkipping line 11753: expected 44 fields, saw 45\\nSkipping line 11776: expected 44 fields, saw 45\\nSkipping line 11797: expected 44 fields, saw 45\\nSkipping line 11809: expected 44 fields, saw 45\\nSkipping line 11882: expected 44 fields, saw 45\\nSkipping line 11915: expected 44 fields, saw 45\\nSkipping line 11917: expected 44 fields, saw 46\\nSkipping line 11929: expected 44 fields, saw 45\\nSkipping line 11956: expected 44 fields, saw 45\\nSkipping line 12031: expected 44 fields, saw 45\\nSkipping line 12047: expected 44 fields, saw 46\\nSkipping line 12160: expected 44 fields, saw 45\\nSkipping line 12180: expected 44 fields, saw 45\\nSkipping line 12184: expected 44 fields, saw 45\\nSkipping line 12224: expected 44 fields, saw 45\\nSkipping line 12227: expected 44 fields, saw 45\\nSkipping line 12233: expected 44 fields, saw 45\\nSkipping line 12251: expected 44 fields, saw 45\\nSkipping line 12256: expected 44 fields, saw 45\\nSkipping line 12257: expected 44 fields, saw 45\\nSkipping line 12259: expected 44 fields, saw 45\\nSkipping line 12355: expected 44 fields, saw 45\\nSkipping line 12378: expected 44 fields, saw 45\\nSkipping line 12398: expected 44 fields, saw 45\\nSkipping line 12486: expected 44 fields, saw 45\\nSkipping line 12516: expected 44 fields, saw 45\\nSkipping line 12588: expected 44 fields, saw 45\\nSkipping line 12595: expected 44 fields, saw 45\\nSkipping line 12614: expected 44 fields, saw 45\\nSkipping line 12642: expected 44 fields, saw 45\\nSkipping line 12701: expected 44 fields, saw 45\\nSkipping line 12741: expected 44 fields, saw 46\\nSkipping line 12771: expected 44 fields, saw 45\\nSkipping line 12777: expected 44 fields, saw 45\\nSkipping line 12802: expected 44 fields, saw 45\\nSkipping line 12892: expected 44 fields, saw 45\\nSkipping line 12910: expected 44 fields, saw 47\\nSkipping line 12982: expected 44 fields, saw 46\\nSkipping line 13024: expected 44 fields, saw 45\\nSkipping line 13052: expected 44 fields, saw 45\\nSkipping line 13056: expected 44 fields, saw 45\\nSkipping line 13158: expected 44 fields, saw 45\\nSkipping line 13170: expected 44 fields, saw 45\\nSkipping line 13171: expected 44 fields, saw 45\\nSkipping line 13186: expected 44 fields, saw 45\\nSkipping line 13240: expected 44 fields, saw 45\\nSkipping line 13262: expected 44 fields, saw 45\\nSkipping line 13374: expected 44 fields, saw 45\\nSkipping line 13407: expected 44 fields, saw 45\\nSkipping line 13477: expected 44 fields, saw 45\\nSkipping line 13540: expected 44 fields, saw 46\\nSkipping line 13569: expected 44 fields, saw 45\\nSkipping line 13617: expected 44 fields, saw 46\\nSkipping line 13651: expected 44 fields, saw 45\\nSkipping line 13663: expected 44 fields, saw 45\\nSkipping line 13754: expected 44 fields, saw 46\\nSkipping line 13775: expected 44 fields, saw 45\\nSkipping line 13804: expected 44 fields, saw 45\\nSkipping line 13828: expected 44 fields, saw 45\\nSkipping line 13865: expected 44 fields, saw 46\\nSkipping line 13883: expected 44 fields, saw 45\\nSkipping line 13929: expected 44 fields, saw 45\\nSkipping line 13948: expected 44 fields, saw 45\\nSkipping line 14022: expected 44 fields, saw 45\\nSkipping line 14127: expected 44 fields, saw 45\\nSkipping line 14148: expected 44 fields, saw 45\\nSkipping line 14173: expected 44 fields, saw 45\\nSkipping line 14243: expected 44 fields, saw 45\\nSkipping line 14254: expected 44 fields, saw 45\\nSkipping line 14318: expected 44 fields, saw 45\\nSkipping line 14320: expected 44 fields, saw 45\\nSkipping line 14354: expected 44 fields, saw 45\\nSkipping line 14434: expected 44 fields, saw 45\\nSkipping line 14456: expected 44 fields, saw 45\\nSkipping line 14479: expected 44 fields, saw 45\\nSkipping line 14565: expected 44 fields, saw 45\\nSkipping line 14572: expected 44 fields, saw 45\\nSkipping line 14616: expected 44 fields, saw 45\\nSkipping line 14636: expected 44 fields, saw 45\\nSkipping line 14642: expected 44 fields, saw 47\\nSkipping line 14644: expected 44 fields, saw 45\\nSkipping line 14649: expected 44 fields, saw 45\\nSkipping line 14670: expected 44 fields, saw 45\\nSkipping line 14688: expected 44 fields, saw 45\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsg784PiHhVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data['imdbRating']\n",
        "x[x > 7] = 8\n",
        "x[x <= 7] = 7\n",
        "data['imdbRating'] = x\n",
        "\n",
        "strs = [\"\" for x in range(14332)]\n",
        "for i, v in enumerate(data['imdbRating']):\n",
        "  strs[i] = str(v)\n",
        "\n",
        "data['imdbRating'] = strs.copy()\n",
        "data['imdbRating_label'] = (data['imdbRating'].apply(lambda x: \"8\" in x)).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t2t7Qeoz4Ip",
        "colab_type": "code",
        "outputId": "e19cedc6-76bc-4f51-f323-4cbc545b2bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# WIDE\n",
        "wide_cols = ['fn', 'ratingCount', 'duration', 'year', 'wordsInTitle']\n",
        "crossed_cols = ()\n",
        "\n",
        "# DEEP DENSE\n",
        "embeddings_cols = [('title', 16), ('wordsInTitle', 16), ('tid', 16)]\n",
        "\n",
        "continuous_cols = [\"duration\",\"year\", \"nrOfUserReviews\", \"nrOfGenre\", \"nrOfNewsArticles\", \"nrOfPhotos\", \"nrOfNominations\", \"nrOfWins\"\n",
        "                   , \"ratingCount\"]\n",
        "\n",
        "standardize_cols = continuous_cols\n",
        "out_dir = 'data/IMDB/wide_deep_data'\n",
        "\n",
        "#TARGET: logistic\n",
        "target = 'imdbRating_label'\n",
        "data.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fn</th>\n",
              "      <th>tid</th>\n",
              "      <th>title</th>\n",
              "      <th>wordsInTitle</th>\n",
              "      <th>url</th>\n",
              "      <th>imdbRating</th>\n",
              "      <th>ratingCount</th>\n",
              "      <th>duration</th>\n",
              "      <th>year</th>\n",
              "      <th>type</th>\n",
              "      <th>nrOfWins</th>\n",
              "      <th>nrOfNominations</th>\n",
              "      <th>nrOfPhotos</th>\n",
              "      <th>nrOfNewsArticles</th>\n",
              "      <th>nrOfUserReviews</th>\n",
              "      <th>nrOfGenre</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adult</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Biography</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>Drama</th>\n",
              "      <th>Family</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>FilmNoir</th>\n",
              "      <th>GameShow</th>\n",
              "      <th>History</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Music</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>News</th>\n",
              "      <th>RealityTV</th>\n",
              "      <th>Romance</th>\n",
              "      <th>SciFi</th>\n",
              "      <th>Short</th>\n",
              "      <th>Sport</th>\n",
              "      <th>TalkShow</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "      <th>imdbRating_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>titles01/tt0012349</td>\n",
              "      <td>tt0012349</td>\n",
              "      <td>Der Vagabund und das Kind (1921)</td>\n",
              "      <td>der vagabund und das kind</td>\n",
              "      <td>http://www.imdb.com/title/tt0012349/</td>\n",
              "      <td>8</td>\n",
              "      <td>40550.0</td>\n",
              "      <td>3240.0</td>\n",
              "      <td>1921.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>96</td>\n",
              "      <td>85</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>titles01/tt0015864</td>\n",
              "      <td>tt0015864</td>\n",
              "      <td>Goldrausch (1925)</td>\n",
              "      <td>goldrausch</td>\n",
              "      <td>http://www.imdb.com/title/tt0015864/</td>\n",
              "      <td>8</td>\n",
              "      <td>45319.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>110</td>\n",
              "      <td>122</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>titles01/tt0017136</td>\n",
              "      <td>tt0017136</td>\n",
              "      <td>Metropolis (1927)</td>\n",
              "      <td>metropolis</td>\n",
              "      <td>http://www.imdb.com/title/tt0017136/</td>\n",
              "      <td>8</td>\n",
              "      <td>81007.0</td>\n",
              "      <td>9180.0</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>428</td>\n",
              "      <td>376</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>titles01/tt0017925</td>\n",
              "      <td>tt0017925</td>\n",
              "      <td>Der General (1926)</td>\n",
              "      <td>der general</td>\n",
              "      <td>http://www.imdb.com/title/tt0017925/</td>\n",
              "      <td>8</td>\n",
              "      <td>37521.0</td>\n",
              "      <td>6420.0</td>\n",
              "      <td>1926.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>123</td>\n",
              "      <td>219</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titles01/tt0021749</td>\n",
              "      <td>tt0021749</td>\n",
              "      <td>Lichter der Großstadt (1931)</td>\n",
              "      <td>lichter der gro stadt</td>\n",
              "      <td>http://www.imdb.com/title/tt0021749/</td>\n",
              "      <td>8</td>\n",
              "      <td>70057.0</td>\n",
              "      <td>5220.0</td>\n",
              "      <td>1931.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   fn        tid  ... Western imdbRating_label\n",
              "0  titles01/tt0012349  tt0012349  ...       0                1\n",
              "1  titles01/tt0015864  tt0015864  ...       0                1\n",
              "2  titles01/tt0017136  tt0017136  ...       0                1\n",
              "3  titles01/tt0017925  tt0017925  ...       0                1\n",
              "4  titles01/tt0021749  tt0021749  ...       0                1\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlemTA5a2Hlh",
        "colab_type": "code",
        "outputId": "ae6e6ac7-6d9d-4074-eb57-d55d2e9da000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# # Adult dataset\n",
        "\n",
        "# DATA_PATH=Path('data')\n",
        "# # the following will all happen if you simply run: python prepare_data.py --dataset adult\n",
        "# DF_adult = pd.read_csv(DATA_PATH/'adult/adult.csv')\n",
        "# DF_adult.columns = [c.replace(\"-\", \"_\") for c in DF_adult.columns]\n",
        "# DF_adult['income_label'] = (DF_adult[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
        "# DF_adult.drop(\"income\", axis=1, inplace=True)\n",
        "# DF_adult['age_buckets'] = pd.cut(DF_adult.age, bins=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65],\n",
        "#     labels=np.arange(9))\n",
        "# out_dir = DATA_PATH/'adult/wide_deep_data/'\n",
        "\n",
        "# # WIDE\n",
        "# wide_cols = ['age_buckets', 'education', 'relationship','workclass','occupation',\n",
        "#     'native_country','gender']\n",
        "# # crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
        "# crossed_cols = ()\n",
        "\n",
        "# # DEEP DENSE\n",
        "# embeddings_cols = [('education',16), ('relationship',16), ('workclass',16),\n",
        "#     ('occupation',16),('native_country',16)]\n",
        "# continuous_cols = [\"age\",\"hours_per_week\"]\n",
        "# standardize_cols = continuous_cols\n",
        "\n",
        "# #TARGET: logistic\n",
        "# target = 'income_label'\n",
        "# DF_adult.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_label</th>\n",
              "      <th>age_buckets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt  ... native_country  income_label age_buckets\n",
              "0   25    Private  226802  ...  United-States             0           0\n",
              "1   38    Private   89814  ...  United-States             0           3\n",
              "2   28  Local-gov  336951  ...  United-States             1           1\n",
              "3   44    Private  160323  ...  United-States             1           4\n",
              "4   18          ?  103497  ...  United-States             0         NaN\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIMNrSDQ-hus",
        "colab_type": "code",
        "outputId": "9bff9da7-3aec-40f0-869a-18d0732cc643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from prepare_data_t1 import prepare_data_adult\n",
        "wd_dataset_imdb = prepare_data_adult(\n",
        "    data, wide_cols,\n",
        "    crossed_cols,\n",
        "    embeddings_cols,\n",
        "    continuous_cols,\n",
        "    standardize_cols,\n",
        "    target, out_dir,\n",
        "    scale=True\n",
        "    )"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide and Deep adult data preparation completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvyOU8Bz15as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0606f61f-c834-470d-bfc3-f840402f2301"
      },
      "source": [
        "# # For adult dataset\n",
        "\n",
        "# from prepare_data_t1 import prepare_data_adult\n",
        "# wd_dataset_imdb = prepare_data_adult(\n",
        "#     DF_adult, wide_cols,\n",
        "#     crossed_cols,\n",
        "#     embeddings_cols,\n",
        "#     continuous_cols,\n",
        "#     standardize_cols,\n",
        "#     target, out_dir,\n",
        "#     scale=True\n",
        "#     )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide and Deep adult data preparation completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QEwRcBf-huv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd_dataset_imdb.keys()\n",
        "wd_dataset_imdb['train'].keys()\n",
        "params = dict()\n",
        "params['wide'] = dict(\n",
        "    wide_dim = wd_dataset_imdb['train']['wide'].shape[1]\n",
        "    )\n",
        "params['deep'] = dict(\n",
        "    embeddings_input = wd_dataset_imdb['cat_embeddings_input'],\n",
        "    embeddings_encoding_dict = wd_dataset_imdb['cat_embeddings_encoding_dict'],\n",
        "    continuous_cols = wd_dataset_imdb['continuous_cols'],\n",
        "    deep_column_idx = wd_dataset_imdb['deep_column_idx'],\n",
        "    hidden_layers = [64,32],\n",
        "    dropout = [0.5]\n",
        "    )\n",
        "\n",
        "model1 = widedeep(**params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWkoCAdg-hux",
        "colab_type": "code",
        "outputId": "41394347-42ad-4103-f631-b108486fc73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "model1"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "widedeep(\n",
              "  (widenn): wide(\n",
              "    (widenn): Linear(in_features=37054, out_features=1, bias=True)\n",
              "  )\n",
              "  (deepnn): deep(\n",
              "    (emb_layer_title): Embedding(14332, 16)\n",
              "    (emb_layer_wordsInTitle): Embedding(13605, 16)\n",
              "    (emb_layer_tid): Embedding(14332, 16)\n",
              "    (dense): Sequential(\n",
              "      (deep_layer0): Sequential(\n",
              "        (0): Linear(in_features=57, out_features=64, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01, inplace)\n",
              "        (2): Dropout(p=0.0)\n",
              "      )\n",
              "      (deep_layer1): Sequential(\n",
              "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01, inplace)\n",
              "        (2): Dropout(p=0.5)\n",
              "      )\n",
              "      (last_linear): Linear(in_features=32, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATFqLhHM-hu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.settings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlNqZIAC-hu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIvbjDOV-hu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_cuda:\n",
        "    model1 = model1.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-TkDPS5xsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(wd_dataset_imdb['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBU98hQY-hu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loader\n",
        "class WideDeepLoader(Dataset):\n",
        "    def __init__(self, data:Dict[str,Any], transform:Optional=None, mode:str='train'):\n",
        "\n",
        "        self.mode = mode\n",
        "        input_types = list(data.keys())\n",
        "        self.input_types = input_types\n",
        "        self.X_wide = data['wide']\n",
        "        if 'deep' in self.input_types: self.X_deep_dense = data['deep']\n",
        "        if self.mode is 'train':\n",
        "            self.Y = data['target']\n",
        "        elif self.mode is 'test':\n",
        "            self.Y = None\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "\n",
        "        xw = self.X_wide[idx]\n",
        "        X = (xw, )\n",
        "        if 'deep' in self.input_types:\n",
        "            xdd = self.X_deep_dense[idx]\n",
        "            X += (xdd,)\n",
        "        if self.mode is 'train':\n",
        "            y  = self.Y[idx]\n",
        "            return X, y\n",
        "        elif self.mode is 'test':\n",
        "            return X\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_wide)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUjGM4r-hu8",
        "colab_type": "code",
        "outputId": "76208739-8019-4a45-9b05-da24c5c43d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_set = WideDeepLoader(wd_dataset_imdb['train'], mode='train')\n",
        "valid_set = WideDeepLoader(wd_dataset_imdb['valid'], mode='train')\n",
        "test_set = WideDeepLoader(wd_dataset_imdb['test'], mode='test')\n",
        "train_set"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.WideDeepLoader at 0x7f88a4fe8e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu6zzl8laOFg",
        "colab_type": "code",
        "outputId": "9b3d368c-54e2-4ea4-ca40-bbe091c75902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1689
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "    batch_size=128,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_set,\n",
        "    batch_size=128,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
        "    batch_size=32,shuffle=False)\n",
        "model1.trainModel(n_epochs=50, train_loader=train_loader, eval_loader=valid_loader)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: 100%|██████████| 68/68 [00:02<00:00, 27.78it/s, acc=0.87, loss=0.12]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 49.93it/s, acc=0.866, loss=0.112]\n",
            "epoch 2: 100%|██████████| 68/68 [00:02<00:00, 28.75it/s, acc=0.922, loss=0.0557]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.73it/s, acc=0.866, loss=0.123]\n",
            "epoch 3: 100%|██████████| 68/68 [00:02<00:00, 29.08it/s, acc=0.995, loss=0.0264]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.18it/s, acc=0.853, loss=0.13]\n",
            "epoch 4: 100%|██████████| 68/68 [00:02<00:00, 28.37it/s, acc=1, loss=0.0156]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 57.62it/s, acc=0.851, loss=0.136]\n",
            "epoch 5: 100%|██████████| 68/68 [00:02<00:00, 28.18it/s, acc=1, loss=0.0119]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.40it/s, acc=0.836, loss=0.146]\n",
            "epoch 6: 100%|██████████| 68/68 [00:02<00:00, 28.76it/s, acc=1, loss=0.0101]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.24it/s, acc=0.833, loss=0.151]\n",
            "epoch 7: 100%|██████████| 68/68 [00:02<00:00, 28.46it/s, acc=1, loss=0.00929]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.73it/s, acc=0.834, loss=0.15]\n",
            "epoch 8: 100%|██████████| 68/68 [00:02<00:00, 29.43it/s, acc=1, loss=0.00903]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 59.27it/s, acc=0.835, loss=0.15]\n",
            "epoch 9: 100%|██████████| 68/68 [00:02<00:00, 28.74it/s, acc=1, loss=0.00921]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.97it/s, acc=0.833, loss=0.15]\n",
            "epoch 10: 100%|██████████| 68/68 [00:02<00:00, 28.42it/s, acc=1, loss=0.0096]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.15it/s, acc=0.83, loss=0.155]\n",
            "epoch 11: 100%|██████████| 68/68 [00:02<00:00, 28.75it/s, acc=1, loss=0.0101]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 53.83it/s, acc=0.832, loss=0.149]\n",
            "epoch 12: 100%|██████████| 68/68 [00:02<00:00, 28.18it/s, acc=1, loss=0.0106]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 57.03it/s, acc=0.833, loss=0.154]\n",
            "epoch 13: 100%|██████████| 68/68 [00:02<00:00, 28.36it/s, acc=1, loss=0.0112]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 57.50it/s, acc=0.826, loss=0.152]\n",
            "epoch 14: 100%|██████████| 68/68 [00:02<00:00, 28.21it/s, acc=1, loss=0.012]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 53.44it/s, acc=0.825, loss=0.153]\n",
            "epoch 15: 100%|██████████| 68/68 [00:02<00:00, 23.36it/s, acc=1, loss=0.0124]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 28.92it/s, acc=0.824, loss=0.152]\n",
            "epoch 16: 100%|██████████| 68/68 [00:02<00:00, 28.60it/s, acc=0.999, loss=0.0125]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.13it/s, acc=0.828, loss=0.151]\n",
            "epoch 17: 100%|██████████| 68/68 [00:02<00:00, 29.69it/s, acc=1, loss=0.0125]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.28it/s, acc=0.817, loss=0.157]\n",
            "epoch 18: 100%|██████████| 68/68 [00:02<00:00, 29.90it/s, acc=1, loss=0.0128]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.95it/s, acc=0.834, loss=0.15]\n",
            "epoch 19: 100%|██████████| 68/68 [00:02<00:00, 29.18it/s, acc=1, loss=0.0126]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.37it/s, acc=0.821, loss=0.155]\n",
            "epoch 20: 100%|██████████| 68/68 [00:02<00:00, 28.93it/s, acc=1, loss=0.0127]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 57.45it/s, acc=0.826, loss=0.155]\n",
            "epoch 21: 100%|██████████| 68/68 [00:02<00:00, 28.69it/s, acc=1, loss=0.0125]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 53.22it/s, acc=0.837, loss=0.143]\n",
            "epoch 22: 100%|██████████| 68/68 [00:02<00:00, 28.92it/s, acc=1, loss=0.0127]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.04it/s, acc=0.821, loss=0.157]\n",
            "epoch 23: 100%|██████████| 68/68 [00:02<00:00, 28.44it/s, acc=0.999, loss=0.0131]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.20it/s, acc=0.825, loss=0.15]\n",
            "epoch 24: 100%|██████████| 68/68 [00:02<00:00, 28.95it/s, acc=0.999, loss=0.013]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.85it/s, acc=0.823, loss=0.154]\n",
            "epoch 25: 100%|██████████| 68/68 [00:02<00:00, 28.55it/s, acc=0.999, loss=0.0132]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 57.78it/s, acc=0.818, loss=0.158]\n",
            "epoch 26: 100%|██████████| 68/68 [00:02<00:00, 28.96it/s, acc=1, loss=0.0128]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.72it/s, acc=0.822, loss=0.153]\n",
            "epoch 27: 100%|██████████| 68/68 [00:02<00:00, 28.96it/s, acc=1, loss=0.0124]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.45it/s, acc=0.821, loss=0.154]\n",
            "epoch 28: 100%|██████████| 68/68 [00:02<00:00, 29.96it/s, acc=0.999, loss=0.0125]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 59.64it/s, acc=0.828, loss=0.153]\n",
            "epoch 29: 100%|██████████| 68/68 [00:02<00:00, 29.37it/s, acc=1, loss=0.0123]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 59.61it/s, acc=0.831, loss=0.148]\n",
            "epoch 30: 100%|██████████| 68/68 [00:02<00:00, 29.05it/s, acc=1, loss=0.0127]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.71it/s, acc=0.827, loss=0.155]\n",
            "epoch 31: 100%|██████████| 68/68 [00:02<00:00, 28.68it/s, acc=1, loss=0.0128]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.15it/s, acc=0.819, loss=0.157]\n",
            "epoch 32: 100%|██████████| 68/68 [00:02<00:00, 28.71it/s, acc=0.999, loss=0.0133]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.50it/s, acc=0.832, loss=0.154]\n",
            "epoch 33: 100%|██████████| 68/68 [00:02<00:00, 28.92it/s, acc=0.999, loss=0.0137]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.57it/s, acc=0.821, loss=0.151]\n",
            "epoch 34: 100%|██████████| 68/68 [00:02<00:00, 28.61it/s, acc=1, loss=0.0139]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.01it/s, acc=0.835, loss=0.151]\n",
            "epoch 35: 100%|██████████| 68/68 [00:02<00:00, 28.53it/s, acc=0.999, loss=0.0144]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.00it/s, acc=0.831, loss=0.149]\n",
            "epoch 36: 100%|██████████| 68/68 [00:02<00:00, 28.50it/s, acc=0.999, loss=0.0148]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.93it/s, acc=0.808, loss=0.158]\n",
            "epoch 37: 100%|██████████| 68/68 [00:02<00:00, 28.35it/s, acc=1, loss=0.0149]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.96it/s, acc=0.825, loss=0.154]\n",
            "epoch 38: 100%|██████████| 68/68 [00:02<00:00, 30.59it/s, acc=0.999, loss=0.0148]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.99it/s, acc=0.825, loss=0.151]\n",
            "epoch 39: 100%|██████████| 68/68 [00:02<00:00, 29.26it/s, acc=0.999, loss=0.0139]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.80it/s, acc=0.834, loss=0.148]\n",
            "epoch 40: 100%|██████████| 68/68 [00:02<00:00, 29.16it/s, acc=0.999, loss=0.014]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.70it/s, acc=0.822, loss=0.153]\n",
            "epoch 41: 100%|██████████| 68/68 [00:02<00:00, 28.87it/s, acc=1, loss=0.0145]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 53.79it/s, acc=0.833, loss=0.15]\n",
            "epoch 42: 100%|██████████| 68/68 [00:02<00:00, 28.75it/s, acc=1, loss=0.0141]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.79it/s, acc=0.831, loss=0.148]\n",
            "epoch 43: 100%|██████████| 68/68 [00:02<00:00, 27.98it/s, acc=0.999, loss=0.0138]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.84it/s, acc=0.821, loss=0.154]\n",
            "epoch 44: 100%|██████████| 68/68 [00:02<00:00, 28.50it/s, acc=1, loss=0.0138]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.07it/s, acc=0.821, loss=0.153]\n",
            "epoch 45: 100%|██████████| 68/68 [00:02<00:00, 28.07it/s, acc=1, loss=0.0139]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 54.80it/s, acc=0.824, loss=0.156]\n",
            "epoch 46: 100%|██████████| 68/68 [00:02<00:00, 28.67it/s, acc=1, loss=0.0136]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.71it/s, acc=0.825, loss=0.152]\n",
            "epoch 47: 100%|██████████| 68/68 [00:02<00:00, 28.94it/s, acc=1, loss=0.0134]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 55.32it/s, acc=0.828, loss=0.152]\n",
            "epoch 48: 100%|██████████| 68/68 [00:02<00:00, 29.08it/s, acc=1, loss=0.0134]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 59.04it/s, acc=0.821, loss=0.153]\n",
            "epoch 49: 100%|██████████| 68/68 [00:02<00:00, 29.45it/s, acc=1, loss=0.0136]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 56.99it/s, acc=0.841, loss=0.146]\n",
            "epoch 50: 100%|██████████| 68/68 [00:02<00:00, 30.52it/s, acc=1, loss=0.0139]\n",
            "valid: 100%|██████████| 23/23 [00:00<00:00, 58.61it/s, acc=0.815, loss=0.155]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKC-WohRkfxG",
        "colab_type": "code",
        "outputId": "c6f2a8ef-8f2b-45d1-a965-81539c35217d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "# Plot global plot_epoch_v,plot_epoch_t,plot_train_loss,plot_val_loss\n",
        "plt.figure(figsize=(14,7))\n",
        "# print(plot_epoch)\n",
        "plt.plot(plot_epoch_t, plot_train_loss, '-', label='E_train')\n",
        "plt.plot(plot_epoch_v, plot_val_loss, '--', label='E_val')\n",
        "plt.xlabel('Epoch', size=15)\n",
        "plt.ylabel('Error', size=15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAGyCAYAAADeceSNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPx8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL8T0rKs3CEr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}