{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide-deep-final_t1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "orw-bvzJ-oei",
        "colab_type": "code",
        "outputId": "ecf98ebe-a0b6-4cd3-e374-9ec10829ed70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjzpHGYv-hug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from pathlib import PosixPath\n",
        "from typing import List, Any, Union, Dict, Optional, Tuple, Generator, Collection\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm,trange\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
        "\n",
        "LRScheduler = _LRScheduler\n",
        "ModelParams = Generator[Tensor,Tensor,Tensor]\n",
        "\n",
        "plot_epoch_t = []\n",
        "plot_train_loss =[]\n",
        "plot_epoch_v = []\n",
        "plot_val_loss = []\n",
        "        \n",
        "      \n",
        "# This is related to wide neural network\n",
        "class wide(nn.Module):\n",
        "    # num_input = number of input\n",
        "    # num_output = number of output\n",
        "    def __init__(self,num_input,num_output):\n",
        "        super(wide, self).__init__()\n",
        "        self.widenn = nn.Linear(num_input,num_output)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.widenn(x)\n",
        "        return out\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc40OVhv-huj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_layer(layer_in,layer_out,dropout):\n",
        "    ly = nn.Sequential(nn.Linear(layer_in, layer_out),nn.LeakyReLU(inplace=True), nn.Dropout(dropout))\n",
        "    return ly\n",
        "\n",
        "# Deep neural network\n",
        "# Code for deep neural network taken from Wide-and-Deep-PyTorch and edited for our dataset\n",
        "class deep(nn.Module):\n",
        "    \n",
        "    # For regression output dimention is 1\n",
        "    def __init__(self, embeddings_input:List[Tuple[str,int,int]],\n",
        "        embeddings_encoding_dict:Dict[str,Any], continuous_cols:List[str],\n",
        "        deep_column_idx:Dict[str,int], hidden_layers:List[int], dropout:List[float],\n",
        "        output_dim=1):\n",
        "        \n",
        "        super(deep, self).__init__()\n",
        "\n",
        "        self.embeddings_input = embeddings_input\n",
        "        self.embeddings_encoding_dict = embeddings_encoding_dict\n",
        "        self.continuous_cols = continuous_cols\n",
        "        self.deep_column_idx = deep_column_idx\n",
        "\n",
        "        for col,val,dim in embeddings_input:\n",
        "            setattr(self, 'emb_layer_'+col, nn.Embedding(val, dim))\n",
        "        input_emb_dim = np.sum([emb[2] for emb in embeddings_input])+len(continuous_cols)\n",
        "        hidden_layers = [input_emb_dim] + hidden_layers\n",
        "        dropout = [0.0] + dropout\n",
        "        self.dense = nn.Sequential()\n",
        "        for i in range(1, len(hidden_layers)):\n",
        "            self.dense.add_module(\n",
        "                'deep_layer{}'.format(i-1),\n",
        "                deep_layer( hidden_layers[i-1], hidden_layers[i], dropout[i-1])\n",
        "                )\n",
        "        self.dense.add_module('last_linear', nn.Linear(hidden_layers[-1], output_dim))\n",
        "\n",
        "    def forward(self, X:Tensor)->Tensor:\n",
        "        emb = [getattr(self, 'emb_layer_'+col)(X[:,self.deep_column_idx[col]].long())\n",
        "               for col,_,_ in self.embeddings_input]\n",
        "        if self.continuous_cols:\n",
        "            cont_idx = [self.deep_column_idx[col] for col in self.continuous_cols]\n",
        "            cont = [X[:, cont_idx].float()]\n",
        "            inp = torch.cat(emb+cont, 1)\n",
        "        else:\n",
        "            inp = torch.cat(emb, 1)\n",
        "        out = self.dense(inp)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npp_ToYy-hum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining wide and deep neural networks\n",
        "\n",
        "class widedeep(nn.Module):\n",
        "    def __init__(self,**params):\n",
        "        super(widedeep,self).__init__()\n",
        "        \n",
        "        self.datasets = {} # dictionary 2 -> wide dataset and deep dataset\n",
        "        self.out_dim = 1 # for regression (predicts the user rate)\n",
        "        self.n_datasets = 1\n",
        "        \n",
        "        # Get parameters for wide dataset\n",
        "        for key,val in params['wide'].items():\n",
        "            setattr(self, key, val) # we are getting wide_dim\n",
        "            \n",
        "        # instantiation of wide objects\n",
        "        self.widenn = wide(\n",
        "            self.wide_dim,\n",
        "            self.out_dim\n",
        "            )\n",
        "        \n",
        "        # Get parameters for deep dataset\n",
        "        for key,val in params['deep'].items():\n",
        "            setattr(self, key, val)\n",
        "        self.datasets['deep'] = self.n_datasets\n",
        "        self.n_datasets+=1\n",
        "        self.deepnn = deep(\n",
        "            self.embeddings_input,\n",
        "            self.embeddings_encoding_dict,\n",
        "            self.continuous_cols,\n",
        "            self.deep_column_idx,\n",
        "            self.hidden_layers,\n",
        "            self.dropout,\n",
        "            self.out_dim\n",
        "        )\n",
        "        \n",
        "    def settings(self):\n",
        "#         method = 'regression'\n",
        "        method = 'logistic'\n",
        "        self.method = method\n",
        "        self.activation, self.criterion = None, F.mse_loss\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "        self.lr_scheduler = None\n",
        "        \n",
        "    def forward(self, X:Tuple[Tensor,...])->Tensor:\n",
        "        \n",
        "        # wide network\n",
        "        wide_input = X[0]\n",
        "        wide_deep = self.widenn(wide_input)\n",
        "        \n",
        "        # Deep network\n",
        "        deep_dense_idx = self.datasets['deep']\n",
        "        deep_dense_out = self.deepnn(X[0])\n",
        "        wide_deep.add_(deep_dense_out)\n",
        "        \n",
        "        # If no activation sigmoid etc. otherwise use activation funct.\n",
        "        return wide_deep\n",
        "    \n",
        "    def trainModel(self,n_epochs,train_loader,eval_loader=None):\n",
        "        train_steps =  (len(train_loader.dataset) // train_loader.batch_size) + 1\n",
        "        global plot_epoch_t,plot_epoch_v,plot_train_loss,plot_val_loss\n",
        "        \n",
        "        plot_epoch_t = []\n",
        "        plot_epoch_v = []\n",
        "        plot_train_loss =[]\n",
        "        plot_val_loss = []\n",
        "        \n",
        "        if eval_loader:\n",
        "            eval_steps =  (len(eval_loader.dataset) // eval_loader.batch_size) + 1\n",
        "            \n",
        "        for epoch in range(n_epochs):\n",
        "            if self.lr_scheduler: self.lr_scheduler.step()\n",
        "            net = self.train()\n",
        "            total, correct, running_loss = 0,0,0\n",
        "            with trange(train_steps) as t:\n",
        "                for i, (data,target) in zip(t, train_loader):\n",
        "                    t.set_description('epoch %i' % (epoch+1))\n",
        "                    X = tuple(x.cuda() for x in data) if use_cuda else data\n",
        "                    y = target.float() if self.method != 'multiclass' else target\n",
        "                    y = y.cuda() if use_cuda else y\n",
        "\n",
        "                    self.optimizer.zero_grad()\n",
        "                    y_pred =  net(X)\n",
        "                    if(self.criterion == F.cross_entropy):\n",
        "                        loss = self.criterion(y_pred, y)\n",
        "                    else:\n",
        "                        loss = self.criterion(y_pred, y.view(-1, 1))\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()\n",
        "                    avg_loss = running_loss/(i+1)\n",
        "\n",
        "                    if self.method != \"regression\":\n",
        "                        total+= y.size(0)\n",
        "                        if self.method == 'logistic':\n",
        "                            y_pred_cat = (y_pred > 0.5).squeeze(1).float()\n",
        "                        if self.method == \"multiclass\":\n",
        "                            _, y_pred_cat = torch.max(y_pred, 1)\n",
        "                        correct+= float((y_pred_cat == y).sum().item())\n",
        "                        t.set_postfix(acc=correct/total, loss=avg_loss)\n",
        "                    else:\n",
        "                        t.set_postfix(loss=np.sqrt(avg_loss))\n",
        "                    plot_epoch_t.append(epoch)\n",
        "                    plot_train_loss.append(avg_loss)\n",
        "\n",
        "            if eval_loader:\n",
        "                total, correct, running_loss = 0,0,0\n",
        "                net = self.eval()\n",
        "                with torch.no_grad():\n",
        "                    with trange(eval_steps) as v:\n",
        "                        for i, (data,target) in zip(v, eval_loader):\n",
        "                            v.set_description('valid')\n",
        "                            X = tuple(x.cuda() for x in data) if use_cuda else data\n",
        "                            y = target.float() if self.method != 'multiclass' else target\n",
        "                            y = y.cuda() if use_cuda else y\n",
        "                            y_pred =  net(X)\n",
        "                            if(self.criterion == F.cross_entropy):\n",
        "                                loss = self.criterion(y_pred, y)\n",
        "                            else:\n",
        "                                loss = self.criterion(y_pred, y.view(-1, 1))\n",
        "                            running_loss += loss.item()\n",
        "                            avg_loss = running_loss/(i+1)\n",
        "                            if self.method != \"regression\":\n",
        "                                total+= y.size(0)\n",
        "                                if self.method == 'logistic':\n",
        "                                    y_pred_cat = (y_pred > 0.5).squeeze(1).float()\n",
        "                                if self.method == \"multiclass\":\n",
        "                                    _, y_pred_cat = torch.max(y_pred, 1)\n",
        "                                correct+= float((y_pred_cat == y).sum().item())\n",
        "                                v.set_postfix(acc=correct/total, loss=avg_loss)\n",
        "                            else:\n",
        "                                v.set_postfix(loss=np.sqrt(avg_loss))\n",
        "                            plot_epoch_v.append(epoch)\n",
        "                            plot_val_loss.append(avg_loss)\n",
        "\n",
        "                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c1m7ZB10W8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e03da5f5-30f3-4020-e9e9-18d98f96b420"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WC7ffn_YM_",
        "colab_type": "code",
        "outputId": "846da81e-9640-4560-8f5f-e9cc831a0066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd My\\ Drive"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw3TfHXi99t0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5f2d102a-64ab-415d-ab2e-fc528f5808c8"
      },
      "source": [
        "cd Wide-and-Deep-PyTorch/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Wide-and-Deep-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doacn11BD0am",
        "colab_type": "code",
        "outputId": "eadd2a7b-5c36-4198-a15b-a07a340aaf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "data = pd.read_csv('data/IMDB/imdb.csv', header=0, error_bad_lines=False)\n",
        "data.columns = [c.replace(\"-\", \"_\") for c in data.columns]\n",
        "\n",
        "data[\"imdbRating\"] = data[\"imdbRating\"].fillna(0).astype(int)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 66: expected 44 fields, saw 46\\nSkipping line 111: expected 44 fields, saw 45\\nSkipping line 198: expected 44 fields, saw 45\\nSkipping line 222: expected 44 fields, saw 46\\nSkipping line 278: expected 44 fields, saw 45\\nSkipping line 396: expected 44 fields, saw 45\\nSkipping line 403: expected 44 fields, saw 45\\nSkipping line 421: expected 44 fields, saw 45\\nSkipping line 437: expected 44 fields, saw 45\\nSkipping line 462: expected 44 fields, saw 46\\nSkipping line 491: expected 44 fields, saw 45\\nSkipping line 515: expected 44 fields, saw 45\\nSkipping line 529: expected 44 fields, saw 45\\nSkipping line 530: expected 44 fields, saw 45\\nSkipping line 558: expected 44 fields, saw 45\\nSkipping line 623: expected 44 fields, saw 45\\nSkipping line 646: expected 44 fields, saw 45\\nSkipping line 663: expected 44 fields, saw 46\\nSkipping line 713: expected 44 fields, saw 45\\nSkipping line 730: expected 44 fields, saw 47\\nSkipping line 791: expected 44 fields, saw 45\\nSkipping line 813: expected 44 fields, saw 45\\nSkipping line 837: expected 44 fields, saw 45\\nSkipping line 861: expected 44 fields, saw 45\\nSkipping line 874: expected 44 fields, saw 45\\nSkipping line 899: expected 44 fields, saw 45\\nSkipping line 917: expected 44 fields, saw 45\\nSkipping line 944: expected 44 fields, saw 46\\nSkipping line 994: expected 44 fields, saw 45\\nSkipping line 1027: expected 44 fields, saw 45\\nSkipping line 1046: expected 44 fields, saw 45\\nSkipping line 1097: expected 44 fields, saw 45\\nSkipping line 1106: expected 44 fields, saw 45\\nSkipping line 1170: expected 44 fields, saw 45\\nSkipping line 1194: expected 44 fields, saw 45\\nSkipping line 1195: expected 44 fields, saw 45\\nSkipping line 1218: expected 44 fields, saw 45\\nSkipping line 1220: expected 44 fields, saw 45\\nSkipping line 1270: expected 44 fields, saw 45\\nSkipping line 1338: expected 44 fields, saw 47\\nSkipping line 1355: expected 44 fields, saw 45\\nSkipping line 1363: expected 44 fields, saw 45\\nSkipping line 1395: expected 44 fields, saw 45\\nSkipping line 1402: expected 44 fields, saw 46\\nSkipping line 1418: expected 44 fields, saw 45\\nSkipping line 1431: expected 44 fields, saw 45\\nSkipping line 1617: expected 44 fields, saw 45\\nSkipping line 1663: expected 44 fields, saw 45\\nSkipping line 1742: expected 44 fields, saw 46\\nSkipping line 1766: expected 44 fields, saw 45\\nSkipping line 1799: expected 44 fields, saw 45\\nSkipping line 1867: expected 44 fields, saw 45\\nSkipping line 1899: expected 44 fields, saw 45\\nSkipping line 1900: expected 44 fields, saw 45\\nSkipping line 1901: expected 44 fields, saw 45\\nSkipping line 1907: expected 44 fields, saw 45\\nSkipping line 1913: expected 44 fields, saw 45\\nSkipping line 1924: expected 44 fields, saw 45\\nSkipping line 1939: expected 44 fields, saw 45\\nSkipping line 1945: expected 44 fields, saw 45\\nSkipping line 1982: expected 44 fields, saw 45\\nSkipping line 2023: expected 44 fields, saw 45\\nSkipping line 2028: expected 44 fields, saw 45\\nSkipping line 2054: expected 44 fields, saw 45\\nSkipping line 2076: expected 44 fields, saw 45\\nSkipping line 2081: expected 44 fields, saw 45\\nSkipping line 2092: expected 44 fields, saw 45\\nSkipping line 2107: expected 44 fields, saw 45\\nSkipping line 2160: expected 44 fields, saw 45\\nSkipping line 2260: expected 44 fields, saw 45\\nSkipping line 2261: expected 44 fields, saw 45\\nSkipping line 2289: expected 44 fields, saw 46\\nSkipping line 2290: expected 44 fields, saw 45\\nSkipping line 2349: expected 44 fields, saw 45\\nSkipping line 2395: expected 44 fields, saw 45\\nSkipping line 2507: expected 44 fields, saw 45\\nSkipping line 2584: expected 44 fields, saw 45\\nSkipping line 2588: expected 44 fields, saw 46\\nSkipping line 2595: expected 44 fields, saw 45\\nSkipping line 2604: expected 44 fields, saw 45\\nSkipping line 2622: expected 44 fields, saw 45\\nSkipping line 2661: expected 44 fields, saw 45\\nSkipping line 2714: expected 44 fields, saw 45\\nSkipping line 2722: expected 44 fields, saw 45\\nSkipping line 2776: expected 44 fields, saw 45\\nSkipping line 2806: expected 44 fields, saw 45\\nSkipping line 2826: expected 44 fields, saw 45\\nSkipping line 2882: expected 44 fields, saw 45\\nSkipping line 2909: expected 44 fields, saw 45\\nSkipping line 3005: expected 44 fields, saw 45\\nSkipping line 3019: expected 44 fields, saw 45\\nSkipping line 3052: expected 44 fields, saw 45\\nSkipping line 3062: expected 44 fields, saw 45\\nSkipping line 3086: expected 44 fields, saw 45\\nSkipping line 3089: expected 44 fields, saw 45\\nSkipping line 3134: expected 44 fields, saw 46\\nSkipping line 3157: expected 44 fields, saw 45\\nSkipping line 3163: expected 44 fields, saw 45\\nSkipping line 3177: expected 44 fields, saw 45\\nSkipping line 3190: expected 44 fields, saw 45\\nSkipping line 3205: expected 44 fields, saw 45\\nSkipping line 3209: expected 44 fields, saw 45\\nSkipping line 3238: expected 44 fields, saw 45\\nSkipping line 3242: expected 44 fields, saw 45\\nSkipping line 3255: expected 44 fields, saw 45\\nSkipping line 3303: expected 44 fields, saw 45\\nSkipping line 3314: expected 44 fields, saw 45\\nSkipping line 3322: expected 44 fields, saw 45\\nSkipping line 3358: expected 44 fields, saw 45\\nSkipping line 3360: expected 44 fields, saw 46\\nSkipping line 3377: expected 44 fields, saw 45\\nSkipping line 3413: expected 44 fields, saw 45\\nSkipping line 3481: expected 44 fields, saw 45\\nSkipping line 3496: expected 44 fields, saw 45\\nSkipping line 3719: expected 44 fields, saw 45\\nSkipping line 3792: expected 44 fields, saw 45\\nSkipping line 3807: expected 44 fields, saw 46\\nSkipping line 3858: expected 44 fields, saw 45\\nSkipping line 3864: expected 44 fields, saw 45\\nSkipping line 3902: expected 44 fields, saw 45\\nSkipping line 3943: expected 44 fields, saw 45\\nSkipping line 3969: expected 44 fields, saw 45\\nSkipping line 4024: expected 44 fields, saw 47\\nSkipping line 4044: expected 44 fields, saw 45\\nSkipping line 4045: expected 44 fields, saw 45\\nSkipping line 4112: expected 44 fields, saw 45\\nSkipping line 4149: expected 44 fields, saw 45\\nSkipping line 4280: expected 44 fields, saw 45\\nSkipping line 4282: expected 44 fields, saw 45\\nSkipping line 4308: expected 44 fields, saw 45\\nSkipping line 4377: expected 44 fields, saw 45\\nSkipping line 4390: expected 44 fields, saw 45\\nSkipping line 4404: expected 44 fields, saw 45\\nSkipping line 4416: expected 44 fields, saw 45\\nSkipping line 4423: expected 44 fields, saw 46\\nSkipping line 4540: expected 44 fields, saw 45\\nSkipping line 4554: expected 44 fields, saw 45\\nSkipping line 4556: expected 44 fields, saw 46\\nSkipping line 4572: expected 44 fields, saw 45\\nSkipping line 4593: expected 44 fields, saw 45\\nSkipping line 4614: expected 44 fields, saw 45\\nSkipping line 4688: expected 44 fields, saw 45\\nSkipping line 4750: expected 44 fields, saw 45\\nSkipping line 4764: expected 44 fields, saw 45\\nSkipping line 4765: expected 44 fields, saw 45\\nSkipping line 4849: expected 44 fields, saw 45\\nSkipping line 4865: expected 44 fields, saw 45\\nSkipping line 4892: expected 44 fields, saw 45\\nSkipping line 4893: expected 44 fields, saw 45\\nSkipping line 4897: expected 44 fields, saw 45\\nSkipping line 4923: expected 44 fields, saw 45\\nSkipping line 4956: expected 44 fields, saw 45\\nSkipping line 4957: expected 44 fields, saw 45\\nSkipping line 4962: expected 44 fields, saw 45\\nSkipping line 4967: expected 44 fields, saw 45\\nSkipping line 4971: expected 44 fields, saw 45\\nSkipping line 5057: expected 44 fields, saw 45\\nSkipping line 5061: expected 44 fields, saw 45\\nSkipping line 5097: expected 44 fields, saw 45\\nSkipping line 5125: expected 44 fields, saw 45\\nSkipping line 5180: expected 44 fields, saw 45\\nSkipping line 5207: expected 44 fields, saw 45\\nSkipping line 5339: expected 44 fields, saw 45\\nSkipping line 5426: expected 44 fields, saw 45\\nSkipping line 5474: expected 44 fields, saw 45\\nSkipping line 5511: expected 44 fields, saw 45\\nSkipping line 5561: expected 44 fields, saw 45\\nSkipping line 5563: expected 44 fields, saw 45\\nSkipping line 5689: expected 44 fields, saw 45\\nSkipping line 5725: expected 44 fields, saw 45\\nSkipping line 5759: expected 44 fields, saw 45\\nSkipping line 5796: expected 44 fields, saw 45\\nSkipping line 5829: expected 44 fields, saw 45\\nSkipping line 5854: expected 44 fields, saw 45\\nSkipping line 5886: expected 44 fields, saw 45\\nSkipping line 5899: expected 44 fields, saw 45\\nSkipping line 5901: expected 44 fields, saw 45\\nSkipping line 5970: expected 44 fields, saw 45\\nSkipping line 5996: expected 44 fields, saw 45\\nSkipping line 6085: expected 44 fields, saw 45\\nSkipping line 6087: expected 44 fields, saw 45\\nSkipping line 6095: expected 44 fields, saw 45\\nSkipping line 6096: expected 44 fields, saw 45\\nSkipping line 6098: expected 44 fields, saw 45\\nSkipping line 6115: expected 44 fields, saw 46\\nSkipping line 6158: expected 44 fields, saw 46\\nSkipping line 6174: expected 44 fields, saw 45\\nSkipping line 6187: expected 44 fields, saw 45\\nSkipping line 6218: expected 44 fields, saw 45\\nSkipping line 6266: expected 44 fields, saw 45\\nSkipping line 6275: expected 44 fields, saw 45\\nSkipping line 6279: expected 44 fields, saw 45\\nSkipping line 6296: expected 44 fields, saw 45\\nSkipping line 6471: expected 44 fields, saw 46\\nSkipping line 6494: expected 44 fields, saw 45\\nSkipping line 6497: expected 44 fields, saw 45\\nSkipping line 6614: expected 44 fields, saw 46\\nSkipping line 6714: expected 44 fields, saw 45\\nSkipping line 6727: expected 44 fields, saw 45\\nSkipping line 6752: expected 44 fields, saw 45\\nSkipping line 6763: expected 44 fields, saw 45\\nSkipping line 6817: expected 44 fields, saw 45\\nSkipping line 6853: expected 44 fields, saw 45\\nSkipping line 6904: expected 44 fields, saw 45\\nSkipping line 6914: expected 44 fields, saw 45\\nSkipping line 6948: expected 44 fields, saw 45\\nSkipping line 6969: expected 44 fields, saw 45\\nSkipping line 6979: expected 44 fields, saw 45\\nSkipping line 7010: expected 44 fields, saw 47\\nSkipping line 7024: expected 44 fields, saw 45\\nSkipping line 7036: expected 44 fields, saw 45\\nSkipping line 7069: expected 44 fields, saw 45\\nSkipping line 7146: expected 44 fields, saw 45\\nSkipping line 7168: expected 44 fields, saw 45\\nSkipping line 7170: expected 44 fields, saw 45\\nSkipping line 7317: expected 44 fields, saw 45\\nSkipping line 7399: expected 44 fields, saw 45\\nSkipping line 7402: expected 44 fields, saw 45\\nSkipping line 7496: expected 44 fields, saw 45\\nSkipping line 7584: expected 44 fields, saw 45\\nSkipping line 7666: expected 44 fields, saw 45\\nSkipping line 7690: expected 44 fields, saw 45\\nSkipping line 7704: expected 44 fields, saw 47\\nSkipping line 7738: expected 44 fields, saw 45\\nSkipping line 7773: expected 44 fields, saw 45\\nSkipping line 7803: expected 44 fields, saw 45\\nSkipping line 7839: expected 44 fields, saw 45\\nSkipping line 7850: expected 44 fields, saw 45\\nSkipping line 7910: expected 44 fields, saw 45\\nSkipping line 7942: expected 44 fields, saw 45\\nSkipping line 7959: expected 44 fields, saw 45\\nSkipping line 8024: expected 44 fields, saw 45\\nSkipping line 8026: expected 44 fields, saw 45\\nSkipping line 8028: expected 44 fields, saw 45\\nSkipping line 8033: expected 44 fields, saw 45\\nSkipping line 8052: expected 44 fields, saw 45\\nSkipping line 8129: expected 44 fields, saw 45\\nSkipping line 8138: expected 44 fields, saw 45\\nSkipping line 8160: expected 44 fields, saw 46\\nSkipping line 8244: expected 44 fields, saw 45\\nSkipping line 8255: expected 44 fields, saw 45\\nSkipping line 8390: expected 44 fields, saw 45\\nSkipping line 8400: expected 44 fields, saw 45\\nSkipping line 8429: expected 44 fields, saw 45\\nSkipping line 8446: expected 44 fields, saw 46\\nSkipping line 8565: expected 44 fields, saw 46\\nSkipping line 8622: expected 44 fields, saw 46\\nSkipping line 8658: expected 44 fields, saw 45\\nSkipping line 8742: expected 44 fields, saw 45\\nSkipping line 8748: expected 44 fields, saw 45\\nSkipping line 8802: expected 44 fields, saw 45\\nSkipping line 8844: expected 44 fields, saw 45\\nSkipping line 8874: expected 44 fields, saw 45\\nSkipping line 8882: expected 44 fields, saw 45\\nSkipping line 8885: expected 44 fields, saw 48\\nSkipping line 8910: expected 44 fields, saw 45\\nSkipping line 8923: expected 44 fields, saw 45\\nSkipping line 8947: expected 44 fields, saw 45\\nSkipping line 8958: expected 44 fields, saw 45\\nSkipping line 9039: expected 44 fields, saw 46\\nSkipping line 9090: expected 44 fields, saw 45\\nSkipping line 9112: expected 44 fields, saw 45\\nSkipping line 9137: expected 44 fields, saw 45\\nSkipping line 9201: expected 44 fields, saw 45\\nSkipping line 9257: expected 44 fields, saw 45\\nSkipping line 9272: expected 44 fields, saw 45\\nSkipping line 9390: expected 44 fields, saw 45\\nSkipping line 9487: expected 44 fields, saw 45\\nSkipping line 9518: expected 44 fields, saw 45\\nSkipping line 9554: expected 44 fields, saw 45\\nSkipping line 9576: expected 44 fields, saw 45\\nSkipping line 9671: expected 44 fields, saw 45\\nSkipping line 9690: expected 44 fields, saw 45\\nSkipping line 9758: expected 44 fields, saw 45\\nSkipping line 9759: expected 44 fields, saw 45\\nSkipping line 9767: expected 44 fields, saw 45\\nSkipping line 9776: expected 44 fields, saw 45\\nSkipping line 9805: expected 44 fields, saw 45\\nSkipping line 9834: expected 44 fields, saw 45\\nSkipping line 9837: expected 44 fields, saw 45\\nSkipping line 9854: expected 44 fields, saw 45\\nSkipping line 9890: expected 44 fields, saw 45\\nSkipping line 9897: expected 44 fields, saw 45\\nSkipping line 9957: expected 44 fields, saw 45\\nSkipping line 9979: expected 44 fields, saw 45\\nSkipping line 9980: expected 44 fields, saw 45\\nSkipping line 10001: expected 44 fields, saw 45\\nSkipping line 10002: expected 44 fields, saw 45\\nSkipping line 10023: expected 44 fields, saw 45\\nSkipping line 10032: expected 44 fields, saw 45\\nSkipping line 10051: expected 44 fields, saw 45\\nSkipping line 10059: expected 44 fields, saw 46\\nSkipping line 10086: expected 44 fields, saw 45\\nSkipping line 10102: expected 44 fields, saw 45\\nSkipping line 10118: expected 44 fields, saw 45\\nSkipping line 10184: expected 44 fields, saw 45\\nSkipping line 10199: expected 44 fields, saw 45\\nSkipping line 10204: expected 44 fields, saw 45\\nSkipping line 10218: expected 44 fields, saw 45\\nSkipping line 10224: expected 44 fields, saw 45\\nSkipping line 10294: expected 44 fields, saw 45\\nSkipping line 10296: expected 44 fields, saw 45\\nSkipping line 10331: expected 44 fields, saw 45\\nSkipping line 10342: expected 44 fields, saw 45\\nSkipping line 10351: expected 44 fields, saw 45\\nSkipping line 10414: expected 44 fields, saw 45\\nSkipping line 10430: expected 44 fields, saw 45\\nSkipping line 10463: expected 44 fields, saw 45\\nSkipping line 10478: expected 44 fields, saw 46\\nSkipping line 10533: expected 44 fields, saw 45\\nSkipping line 10536: expected 44 fields, saw 45\\nSkipping line 10539: expected 44 fields, saw 45\\nSkipping line 10549: expected 44 fields, saw 45\\nSkipping line 10582: expected 44 fields, saw 45\\nSkipping line 10588: expected 44 fields, saw 45\\nSkipping line 10598: expected 44 fields, saw 45\\nSkipping line 10660: expected 44 fields, saw 45\\nSkipping line 10733: expected 44 fields, saw 45\\nSkipping line 10806: expected 44 fields, saw 45\\nSkipping line 10862: expected 44 fields, saw 45\\nSkipping line 10905: expected 44 fields, saw 45\\nSkipping line 10993: expected 44 fields, saw 45\\nSkipping line 11070: expected 44 fields, saw 45\\nSkipping line 11084: expected 44 fields, saw 45\\nSkipping line 11110: expected 44 fields, saw 45\\nSkipping line 11123: expected 44 fields, saw 45\\nSkipping line 11128: expected 44 fields, saw 45\\nSkipping line 11129: expected 44 fields, saw 45\\nSkipping line 11196: expected 44 fields, saw 45\\nSkipping line 11210: expected 44 fields, saw 45\\nSkipping line 11254: expected 44 fields, saw 45\\nSkipping line 11290: expected 44 fields, saw 45\\nSkipping line 11365: expected 44 fields, saw 45\\nSkipping line 11433: expected 44 fields, saw 45\\nSkipping line 11434: expected 44 fields, saw 45\\nSkipping line 11469: expected 44 fields, saw 45\\nSkipping line 11475: expected 44 fields, saw 45\\nSkipping line 11480: expected 44 fields, saw 45\\nSkipping line 11513: expected 44 fields, saw 45\\nSkipping line 11522: expected 44 fields, saw 45\\nSkipping line 11553: expected 44 fields, saw 45\\nSkipping line 11610: expected 44 fields, saw 45\\nSkipping line 11641: expected 44 fields, saw 45\\nSkipping line 11655: expected 44 fields, saw 46\\nSkipping line 11689: expected 44 fields, saw 45\\nSkipping line 11753: expected 44 fields, saw 45\\nSkipping line 11776: expected 44 fields, saw 45\\nSkipping line 11797: expected 44 fields, saw 45\\nSkipping line 11809: expected 44 fields, saw 45\\nSkipping line 11882: expected 44 fields, saw 45\\nSkipping line 11915: expected 44 fields, saw 45\\nSkipping line 11917: expected 44 fields, saw 46\\nSkipping line 11929: expected 44 fields, saw 45\\nSkipping line 11956: expected 44 fields, saw 45\\nSkipping line 12031: expected 44 fields, saw 45\\nSkipping line 12047: expected 44 fields, saw 46\\nSkipping line 12160: expected 44 fields, saw 45\\nSkipping line 12180: expected 44 fields, saw 45\\nSkipping line 12184: expected 44 fields, saw 45\\nSkipping line 12224: expected 44 fields, saw 45\\nSkipping line 12227: expected 44 fields, saw 45\\nSkipping line 12233: expected 44 fields, saw 45\\nSkipping line 12251: expected 44 fields, saw 45\\nSkipping line 12256: expected 44 fields, saw 45\\nSkipping line 12257: expected 44 fields, saw 45\\nSkipping line 12259: expected 44 fields, saw 45\\nSkipping line 12355: expected 44 fields, saw 45\\nSkipping line 12378: expected 44 fields, saw 45\\nSkipping line 12398: expected 44 fields, saw 45\\nSkipping line 12486: expected 44 fields, saw 45\\nSkipping line 12516: expected 44 fields, saw 45\\nSkipping line 12588: expected 44 fields, saw 45\\nSkipping line 12595: expected 44 fields, saw 45\\nSkipping line 12614: expected 44 fields, saw 45\\nSkipping line 12642: expected 44 fields, saw 45\\nSkipping line 12701: expected 44 fields, saw 45\\nSkipping line 12741: expected 44 fields, saw 46\\nSkipping line 12771: expected 44 fields, saw 45\\nSkipping line 12777: expected 44 fields, saw 45\\nSkipping line 12802: expected 44 fields, saw 45\\nSkipping line 12892: expected 44 fields, saw 45\\nSkipping line 12910: expected 44 fields, saw 47\\nSkipping line 12982: expected 44 fields, saw 46\\nSkipping line 13024: expected 44 fields, saw 45\\nSkipping line 13052: expected 44 fields, saw 45\\nSkipping line 13056: expected 44 fields, saw 45\\nSkipping line 13158: expected 44 fields, saw 45\\nSkipping line 13170: expected 44 fields, saw 45\\nSkipping line 13171: expected 44 fields, saw 45\\nSkipping line 13186: expected 44 fields, saw 45\\nSkipping line 13240: expected 44 fields, saw 45\\nSkipping line 13262: expected 44 fields, saw 45\\nSkipping line 13374: expected 44 fields, saw 45\\nSkipping line 13407: expected 44 fields, saw 45\\nSkipping line 13477: expected 44 fields, saw 45\\nSkipping line 13540: expected 44 fields, saw 46\\nSkipping line 13569: expected 44 fields, saw 45\\nSkipping line 13617: expected 44 fields, saw 46\\nSkipping line 13651: expected 44 fields, saw 45\\nSkipping line 13663: expected 44 fields, saw 45\\nSkipping line 13754: expected 44 fields, saw 46\\nSkipping line 13775: expected 44 fields, saw 45\\nSkipping line 13804: expected 44 fields, saw 45\\nSkipping line 13828: expected 44 fields, saw 45\\nSkipping line 13865: expected 44 fields, saw 46\\nSkipping line 13883: expected 44 fields, saw 45\\nSkipping line 13929: expected 44 fields, saw 45\\nSkipping line 13948: expected 44 fields, saw 45\\nSkipping line 14022: expected 44 fields, saw 45\\nSkipping line 14127: expected 44 fields, saw 45\\nSkipping line 14148: expected 44 fields, saw 45\\nSkipping line 14173: expected 44 fields, saw 45\\nSkipping line 14243: expected 44 fields, saw 45\\nSkipping line 14254: expected 44 fields, saw 45\\nSkipping line 14318: expected 44 fields, saw 45\\nSkipping line 14320: expected 44 fields, saw 45\\nSkipping line 14354: expected 44 fields, saw 45\\nSkipping line 14434: expected 44 fields, saw 45\\nSkipping line 14456: expected 44 fields, saw 45\\nSkipping line 14479: expected 44 fields, saw 45\\nSkipping line 14565: expected 44 fields, saw 45\\nSkipping line 14572: expected 44 fields, saw 45\\nSkipping line 14616: expected 44 fields, saw 45\\nSkipping line 14636: expected 44 fields, saw 45\\nSkipping line 14642: expected 44 fields, saw 47\\nSkipping line 14644: expected 44 fields, saw 45\\nSkipping line 14649: expected 44 fields, saw 45\\nSkipping line 14670: expected 44 fields, saw 45\\nSkipping line 14688: expected 44 fields, saw 45\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsg784PiHhVK",
        "colab_type": "code",
        "outputId": "89577812-eab7-40ef-ff5c-8d13afeeb522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "x = data['imdbRating']\n",
        "# data[data['imdbRating'] > 7] = 1\n",
        "x[x > 7] = 8\n",
        "x[x <= 7] = 7\n",
        "data['imdbRating'] = x\n",
        "\n",
        "strs = [\"\" for x in range(14332)]\n",
        "# print(strs)\n",
        "\n",
        "for i, v in enumerate(data['imdbRating']):\n",
        "  strs[i] = str(v)\n",
        "\n",
        "data['imdbRating'] = strs.copy()\n",
        "# print(data['imdbRating'])\n",
        "data['imdbRating_label'] = (data['imdbRating'].apply(lambda x: \"8\" in x)).astype(int)\n",
        "# print(data['imdbRating_label'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t2t7Qeoz4Ip",
        "colab_type": "code",
        "outputId": "c0f14eeb-04e5-4096-b081-946af2d3df53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# WIDE\n",
        "wide_cols = ['fn', 'ratingCount', 'duration', 'year', 'wordsInTitle']\n",
        "\n",
        "# crossed_cols = (['fn', 'title'], ['fn', 'title'])\n",
        "# crossed_cols = (['tid', 'wordsInTitle'], ['tid','duration'], ['tid', 'year'])\n",
        "crossed_cols = ()\n",
        "\n",
        "# DEEP DENSE\n",
        "embeddings_cols = [('title', 16), ('wordsInTitle', 16), ('tid', 16)]\n",
        "\n",
        "continuous_cols = [\"duration\",\"year\", \"nrOfUserReviews\", \"nrOfGenre\", \"nrOfNewsArticles\", \"nrOfPhotos\", \"nrOfNominations\", \"nrOfWins\", \"ratingCount\"]\n",
        "\n",
        "standardize_cols = continuous_cols\n",
        "out_dir = 'data/IMDB/wide_deep_data'\n",
        "\n",
        "#TARGET: logistic\n",
        "target = 'imdbRating_label'\n",
        "data.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fn</th>\n",
              "      <th>tid</th>\n",
              "      <th>title</th>\n",
              "      <th>wordsInTitle</th>\n",
              "      <th>url</th>\n",
              "      <th>imdbRating</th>\n",
              "      <th>ratingCount</th>\n",
              "      <th>duration</th>\n",
              "      <th>year</th>\n",
              "      <th>type</th>\n",
              "      <th>nrOfWins</th>\n",
              "      <th>nrOfNominations</th>\n",
              "      <th>nrOfPhotos</th>\n",
              "      <th>nrOfNewsArticles</th>\n",
              "      <th>nrOfUserReviews</th>\n",
              "      <th>nrOfGenre</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adult</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Biography</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>Drama</th>\n",
              "      <th>Family</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>FilmNoir</th>\n",
              "      <th>GameShow</th>\n",
              "      <th>History</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Music</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>News</th>\n",
              "      <th>RealityTV</th>\n",
              "      <th>Romance</th>\n",
              "      <th>SciFi</th>\n",
              "      <th>Short</th>\n",
              "      <th>Sport</th>\n",
              "      <th>TalkShow</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "      <th>imdbRating_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>titles01/tt0012349</td>\n",
              "      <td>tt0012349</td>\n",
              "      <td>Der Vagabund und das Kind (1921)</td>\n",
              "      <td>der vagabund und das kind</td>\n",
              "      <td>http://www.imdb.com/title/tt0012349/</td>\n",
              "      <td>8</td>\n",
              "      <td>40550.0</td>\n",
              "      <td>3240.0</td>\n",
              "      <td>1921.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>96</td>\n",
              "      <td>85</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>titles01/tt0015864</td>\n",
              "      <td>tt0015864</td>\n",
              "      <td>Goldrausch (1925)</td>\n",
              "      <td>goldrausch</td>\n",
              "      <td>http://www.imdb.com/title/tt0015864/</td>\n",
              "      <td>8</td>\n",
              "      <td>45319.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>110</td>\n",
              "      <td>122</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>titles01/tt0017136</td>\n",
              "      <td>tt0017136</td>\n",
              "      <td>Metropolis (1927)</td>\n",
              "      <td>metropolis</td>\n",
              "      <td>http://www.imdb.com/title/tt0017136/</td>\n",
              "      <td>8</td>\n",
              "      <td>81007.0</td>\n",
              "      <td>9180.0</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>428</td>\n",
              "      <td>376</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>titles01/tt0017925</td>\n",
              "      <td>tt0017925</td>\n",
              "      <td>Der General (1926)</td>\n",
              "      <td>der general</td>\n",
              "      <td>http://www.imdb.com/title/tt0017925/</td>\n",
              "      <td>8</td>\n",
              "      <td>37521.0</td>\n",
              "      <td>6420.0</td>\n",
              "      <td>1926.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>123</td>\n",
              "      <td>219</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>titles01/tt0021749</td>\n",
              "      <td>tt0021749</td>\n",
              "      <td>Lichter der Grostadt (1931)</td>\n",
              "      <td>lichter der gro stadt</td>\n",
              "      <td>http://www.imdb.com/title/tt0021749/</td>\n",
              "      <td>8</td>\n",
              "      <td>70057.0</td>\n",
              "      <td>5220.0</td>\n",
              "      <td>1931.0</td>\n",
              "      <td>video.movie</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   fn        tid  ... Western imdbRating_label\n",
              "0  titles01/tt0012349  tt0012349  ...       0                1\n",
              "1  titles01/tt0015864  tt0015864  ...       0                1\n",
              "2  titles01/tt0017136  tt0017136  ...       0                1\n",
              "3  titles01/tt0017925  tt0017925  ...       0                1\n",
              "4  titles01/tt0021749  tt0021749  ...       0                1\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlemTA5a2Hlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adult dataset\n",
        "\n",
        "# DATA_PATH=Path('data')\n",
        "# # the following will all happen if you simply run: python prepare_data.py --dataset adult\n",
        "# DF_adult = pd.read_csv(DATA_PATH/'adult/adult.csv')\n",
        "# DF_adult.columns = [c.replace(\"-\", \"_\") for c in DF_adult.columns]\n",
        "# DF_adult['income_label'] = (DF_adult[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
        "# DF_adult.drop(\"income\", axis=1, inplace=True)\n",
        "# DF_adult['age_buckets'] = pd.cut(DF_adult.age, bins=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65],\n",
        "#     labels=np.arange(9))\n",
        "# out_dir = DATA_PATH/'adult/wide_deep_data/'\n",
        "\n",
        "# # WIDE\n",
        "# wide_cols = ['age_buckets', 'education', 'relationship','workclass','occupation',\n",
        "#     'native_country','gender']\n",
        "# # crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
        "# crossed_cols = ()\n",
        "\n",
        "# # DEEP DENSE\n",
        "# embeddings_cols = [('education',16), ('relationship',16), ('workclass',16),\n",
        "#     ('occupation',16),('native_country',16)]\n",
        "# continuous_cols = [\"age\",\"hours_per_week\"]\n",
        "# standardize_cols = continuous_cols\n",
        "\n",
        "# #TARGET: logistic\n",
        "# target = 'income_label'\n",
        "# DF_adult.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIMNrSDQ-hus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9379d2ca-7bcb-4434-86c2-33afb55ebd32"
      },
      "source": [
        "from prepare_data_t1 import prepare_data_adult\n",
        "wd_dataset_imdb = prepare_data_adult(\n",
        "    data, wide_cols,\n",
        "    crossed_cols,\n",
        "    embeddings_cols,\n",
        "    continuous_cols,\n",
        "    standardize_cols,\n",
        "    target, out_dir,\n",
        "    scale=True\n",
        "    )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wide and Deep adult data preparation completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvyOU8Bz15as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For adult dataset\n",
        "\n",
        "# from prepare_data_t1 import prepare_data_adult\n",
        "# wd_dataset_imdb = prepare_data_adult(\n",
        "#     DF_adult, wide_cols,\n",
        "#     crossed_cols,\n",
        "#     embeddings_cols,\n",
        "#     continuous_cols,\n",
        "#     standardize_cols,\n",
        "#     target, out_dir,\n",
        "#     scale=True\n",
        "#     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QEwRcBf-huv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd_dataset_imdb.keys()\n",
        "wd_dataset_imdb['train'].keys()\n",
        "params = dict()\n",
        "params['wide'] = dict(\n",
        "    wide_dim = wd_dataset_imdb['train']['wide'].shape[1]\n",
        "    )\n",
        "params['deep'] = dict(\n",
        "    embeddings_input = wd_dataset_imdb['cat_embeddings_input'],\n",
        "    embeddings_encoding_dict = wd_dataset_imdb['cat_embeddings_encoding_dict'],\n",
        "    continuous_cols = wd_dataset_imdb['continuous_cols'],\n",
        "    deep_column_idx = wd_dataset_imdb['deep_column_idx'],\n",
        "    hidden_layers = [64,32],\n",
        "    dropout = [0.5]\n",
        "    )\n",
        "\n",
        "model1 = widedeep(**params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWkoCAdg-hux",
        "colab_type": "code",
        "outputId": "5b435b73-daee-4179-b7f5-4782f5392f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "model1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "widedeep(\n",
              "  (widenn): wide(\n",
              "    (widenn): Linear(in_features=37054, out_features=1, bias=True)\n",
              "  )\n",
              "  (deepnn): deep(\n",
              "    (emb_layer_title): Embedding(14332, 16)\n",
              "    (emb_layer_wordsInTitle): Embedding(13605, 16)\n",
              "    (emb_layer_tid): Embedding(14332, 16)\n",
              "    (dense): Sequential(\n",
              "      (deep_layer0): Sequential(\n",
              "        (0): Linear(in_features=57, out_features=64, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01, inplace)\n",
              "        (2): Dropout(p=0.0)\n",
              "      )\n",
              "      (deep_layer1): Sequential(\n",
              "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01, inplace)\n",
              "        (2): Dropout(p=0.5)\n",
              "      )\n",
              "      (last_linear): Linear(in_features=32, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATFqLhHM-hu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.settings()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlNqZIAC-hu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIvbjDOV-hu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_cuda:\n",
        "    model1 = model1.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-TkDPS5xsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(wd_dataset_imdb['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBU98hQY-hu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loader\n",
        "class WideDeepLoader(Dataset):\n",
        "    def __init__(self, data:Dict[str,Any], transform:Optional=None, mode:str='train'):\n",
        "\n",
        "        self.mode = mode\n",
        "        input_types = list(data.keys())\n",
        "        self.input_types = input_types\n",
        "        self.X_wide = data['wide']\n",
        "        if 'deep' in self.input_types: self.X_deep_dense = data['deep']\n",
        "        if self.mode is 'train':\n",
        "            self.Y = data['target']\n",
        "        elif self.mode is 'test':\n",
        "            self.Y = None\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "\n",
        "        xw = self.X_wide[idx]\n",
        "        X = (xw, )\n",
        "        if 'deep' in self.input_types:\n",
        "            xdd = self.X_deep_dense[idx]\n",
        "            X += (xdd,)\n",
        "        if self.mode is 'train':\n",
        "            y  = self.Y[idx]\n",
        "            return X, y\n",
        "        elif self.mode is 'test':\n",
        "            return X\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_wide)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUjGM4r-hu8",
        "colab_type": "code",
        "outputId": "e53f9fd0-cf4a-49b0-ceb7-6f62d1541311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_set = WideDeepLoader(wd_dataset_imdb['train'], mode='train')\n",
        "valid_set = WideDeepLoader(wd_dataset_imdb['valid'], mode='train')\n",
        "test_set = WideDeepLoader(wd_dataset_imdb['test'], mode='test')\n",
        "train_set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.WideDeepLoader at 0x7fa41e482c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu6zzl8laOFg",
        "colab_type": "code",
        "outputId": "0b04b0ba-fcbe-49fc-8e23-9e899253d675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "    batch_size=128,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_set,\n",
        "    batch_size=128,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
        "    batch_size=32,shuffle=False)\n",
        "model1.trainModel(n_epochs=10, train_loader=train_loader, eval_loader=valid_loader)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: 100%|| 68/68 [00:02<00:00, 28.61it/s, acc=0.871, loss=0.111]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 52.88it/s, acc=0.866, loss=0.11]\n",
            "epoch 2: 100%|| 68/68 [00:02<00:00, 29.45it/s, acc=0.93, loss=0.0506]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 52.53it/s, acc=0.863, loss=0.125]\n",
            "epoch 3: 100%|| 68/68 [00:02<00:00, 27.62it/s, acc=0.996, loss=0.0232]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 54.18it/s, acc=0.844, loss=0.145]\n",
            "epoch 4: 100%|| 68/68 [00:02<00:00, 28.15it/s, acc=1, loss=0.0149]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 52.59it/s, acc=0.838, loss=0.148]\n",
            "epoch 5: 100%|| 68/68 [00:02<00:00, 28.02it/s, acc=1, loss=0.0122]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 50.52it/s, acc=0.826, loss=0.154]\n",
            "epoch 6: 100%|| 68/68 [00:02<00:00, 27.97it/s, acc=1, loss=0.011]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 54.39it/s, acc=0.826, loss=0.158]\n",
            "epoch 7: 100%|| 68/68 [00:02<00:00, 28.57it/s, acc=1, loss=0.01]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 52.26it/s, acc=0.821, loss=0.158]\n",
            "epoch 8: 100%|| 68/68 [00:02<00:00, 28.07it/s, acc=1, loss=0.00953]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 57.07it/s, acc=0.827, loss=0.156]\n",
            "epoch 9: 100%|| 68/68 [00:02<00:00, 28.10it/s, acc=1, loss=0.00964]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 49.28it/s, acc=0.821, loss=0.158]\n",
            "epoch 10: 100%|| 68/68 [00:02<00:00, 28.98it/s, acc=1, loss=0.00989]\n",
            "valid: 100%|| 23/23 [00:00<00:00, 55.25it/s, acc=0.821, loss=0.159]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKC-WohRkfxG",
        "colab_type": "code",
        "outputId": "58aa5f53-9e26-4ccc-8edf-070afe7f651c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "# Plot global plot_epoch_v,plot_epoch_t,plot_train_loss,plot_val_loss\n",
        "plt.figure(figsize=(14,7))\n",
        "# print(plot_epoch)\n",
        "plt.plot(plot_epoch_t, plot_train_loss, '-', label='E_train')\n",
        "plt.plot(plot_epoch_v, plot_val_loss, '--', label='E_val')\n",
        "plt.xlabel('Epoch', size=15)\n",
        "plt.ylabel('Error', size=15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAGyCAYAAAAMIe7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL8T0rKs3CEr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}